[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Brandon Scott",
    "section": "",
    "text": "I love learning and teaching so this blog is my motivation to learn new topics and learn how to best convey the messages I received. I hope to demonstrate in this blog an analytical way to approach problems. I like using a tool-box method in my posts, approaching a problem and demonstrating how various tools can be used to solve it. I hope you enjoy this blog as much as I enjoy writing it!"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Brandon Scott",
    "section": "Education",
    "text": "Education\nTexas A&M University M.S. in Statistics | January 2023 - May 2025\nUtah Valley University M.S. in Computer Science | September 2021 - April 2022 (transferred)\nBrigham Young University B.S. in Actuarial Science | September 2017 - April 2021"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Brandon Scott",
    "section": "Experience",
    "text": "Experience\nUber | Data Analyst | October 2022 - Present AdvancedMD | Senior Business Analyst | July 2021 - October 2022"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Bayesian Bandit",
    "section": "",
    "text": "An Analysis of Heart Disease Data\n\n\n\nanalysis\n\n\nbayesian\n\n\npython\n\n\nclassification\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Analysis of TA-MU Hotel Booking Data\n\n\n\nanalysis\n\n\nbayesian\n\n\npython\n\n\nclassification\n\n\n\n\n\n\n\n\n\n\nApr 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to my blog!\n\n\n\nwelcome\n\n\nbayesian\n\n\n\n\n\n\n\nBrandon Scott\n\n\nMar 6, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/heart-disease/heart_disease_analysis.html",
    "href": "posts/heart-disease/heart_disease_analysis.html",
    "title": "An Analysis of Heart Disease Data",
    "section": "",
    "text": "Abstract\nUsing data collected from hospitals in India, we demonstrate the usefulness of logistic regression in classifying patients with cardiovascular disease based on features collected by the hospital. We first present the classic approach to logistic regression (frequentist appraoch) followed by a demonstration of a bayesian approach to binary classification data. Our analysis shows that the given features and proposed inference approach prove viable and accurate methods in detecting cardiovascular disease in the sampled patients.\nData can be found here\n\n\nIntroduction\nTests are widely used in hospitals around the world to increase the effectiveness of preventitve care. Behind these tests are statistical methods that aid doctors and other healthcare professionals in properly administering care by correctly identifying health problems. In this analysis, we analyze a dataset collected from hospitals in India that were looking for ways to identify cardiovascular diseases in their patients. The goal is to provide the hospitals with 2 things: an accurate model that predicts the presence of cardiovascular disease, and a model that helps doctors know what symptoms to watch out for when helping patients, further alerting them to either receive a test for possible cardiovascular disease or dismiss those concerns.\nBelow is the first 5 rows of the dataset that we will be analyzing.\n\n\n\n\n\n\n\n\n\npatientid\nage\ngender\nchestpain\nrestingBP\nserumcholestrol\nfastingbloodsugar\nrestingrelectro\nmaxheartrate\nexerciseangia\noldpeak\nslope\nnoofmajorvessels\ntarget\n\n\n\n\n0\n103368\n53\n1\n2\n171\n0\n0\n1\n147\n0\n5.3\n3\n3\n1\n\n\n1\n119250\n40\n1\n0\n94\n229\n0\n1\n115\n0\n3.7\n1\n1\n0\n\n\n2\n119372\n49\n1\n2\n133\n142\n0\n0\n202\n1\n5.0\n1\n0\n0\n\n\n3\n132514\n43\n1\n0\n138\n295\n1\n1\n153\n0\n3.2\n2\n2\n1\n\n\n4\n146211\n31\n1\n1\n199\n0\n0\n2\n136\n0\n5.3\n3\n2\n1\n\n\n\n\n\n\n\nOf the 14 columns listed above, 1 is our target column (1 for disease and 0 for no disease), 12 features that we will use to gather inference on the target, and 1 column for patientids (unique key). Gender is encoded 1 for male and 0 for female. To ensure our analysis goes smoothly, we should validate that there are no null values. If there are any, we need to construct a strategy for conserving as much information as possible. Output for the number of null values for each column is found below.\n\n\npatientid            0\nage                  0\ngender               0\nchestpain            0\nrestingBP            0\nserumcholestrol      0\nfastingbloodsugar    0\nrestingrelectro      0\nmaxheartrate         0\nexerciseangia        0\noldpeak              0\nslope                0\nnoofmajorvessels     0\ntarget               0\ndtype: int64\n\n\nThe output shows that there are no null values for any of the columns in our dataset, so we can move onto the next step of data prep which is to verify the datatypes of each column. Essentially, we are verifying that all columns have data values that are to be expected (i.e. integers types for numeric columns). Output for this test is shown below.\n\n\npatientid              int64\nage                    int64\ngender                 int64\nchestpain              int64\nrestingBP              int64\nserumcholestrol        int64\nfastingbloodsugar      int64\nrestingrelectro        int64\nmaxheartrate           int64\nexerciseangia          int64\noldpeak              float64\nslope                  int64\nnoofmajorvessels       int64\ntarget                 int64\ndtype: object\n\n\nThere doesn’t appear to be any unexpected datatypes in the dataset, so we can verify this step of data prep. More data prep can always be explored to ensure viable data for data analysis purposes, but for now we shall conclude these 2 steps are sufficient and proceed to our analysis of the data.\n\n\nExploratory Data Analysis\nTo begin our analysis, we will perform exploratory data analysis (EDA) to gather more information about how to best model our data. Below is a descriptive statistics table for our columns.\n\n\n\n\n\n\n\n\n\npatientid\nage\ngender\nchestpain\nrestingBP\nserumcholestrol\nfastingbloodsugar\nrestingrelectro\nmaxheartrate\nexerciseangia\noldpeak\nslope\nnoofmajorvessels\ntarget\n\n\n\n\ncount\n1.000000e+03\n1000.00000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n5.048704e+06\n49.24200\n0.765000\n0.980000\n151.747000\n311.447000\n0.296000\n0.748000\n145.477000\n0.498000\n2.707700\n1.540000\n1.222000\n0.580000\n\n\nstd\n2.895905e+06\n17.86473\n0.424211\n0.953157\n29.965228\n132.443801\n0.456719\n0.770123\n34.190268\n0.500246\n1.720753\n1.003697\n0.977585\n0.493805\n\n\nmin\n1.033680e+05\n20.00000\n0.000000\n0.000000\n94.000000\n0.000000\n0.000000\n0.000000\n71.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n2.536440e+06\n34.00000\n1.000000\n0.000000\n129.000000\n235.750000\n0.000000\n0.000000\n119.750000\n0.000000\n1.300000\n1.000000\n0.000000\n0.000000\n\n\n50%\n4.952508e+06\n49.00000\n1.000000\n1.000000\n147.000000\n318.000000\n0.000000\n1.000000\n146.000000\n0.000000\n2.400000\n2.000000\n1.000000\n1.000000\n\n\n75%\n7.681877e+06\n64.25000\n1.000000\n2.000000\n181.000000\n404.250000\n1.000000\n1.000000\n175.000000\n1.000000\n4.100000\n2.000000\n2.000000\n1.000000\n\n\nmax\n9.990855e+06\n80.00000\n1.000000\n3.000000\n200.000000\n602.000000\n1.000000\n2.000000\n202.000000\n1.000000\n6.200000\n3.000000\n3.000000\n1.000000\n\n\n\n\n\n\n\nViewing the average for target, we get a value of .58, meaning a little more than half of our dataset contains presence of cardiovascular disease. Returning to the age column, we see that the average age is around 49 years, with the oldest being 80 and the youngest being 20. In addition, most of our dataset is compromised of males (about 77% of the dataset). Further domain knowledge is necessary to identify whether the other features respective statistics are “good” or “bad” values (healthy or not healthy).\nWhile the tabular statistical information above is valiable, visual representations of the data are valiable to present so that we can quickly digest how our data looks. Below is a bar plot of the target values.\n\n\n\n\n\nFigure 3.1: Bar plot of target count using seaborn. As noted from the summary statistics, the dataset contains more 1s than 0s for target, indicating a higher presence of heart disease in the sample.\n\n\n\n\nWe can now visually see the imbalance of data in our dataset. There appears to be about 150 more 1s than 0s in the dataset. We will demonstrate later in the analysis how logistic regression is a good choice for handling unbalanced datasets. For now, we will continue to explore the dataset. While we clearly see above that there is a difference between the number of patients with and without heart disease, we should discover more information about who pertains to each target value. To do this, we can use a box-and-whisker plot to view the distribution of a variable separated by target value. Below is a box-and-whisker plot of the age distribution for 0 and 1 target values respectively.\n\n\n\n\n\nFigure 3.2: Box-and-whisker plot of the distribution of age between the 2 target values. While the bar plot in Figure 3.1 showed a difference in the number of each target value, this plot shows there is no big difference in age distribution between the 2 target values.\n\n\n\n\nThe median for each respective target value appears to be 50, with a bit more variance for target value 0 than in target value 1, probably due to a smaller sample size. Nonetheless, we see that the age distribution for those who do not have and do have heart disease appear to be approximately the same.\nTo speed up the process of EDA, we can plot several box-and-whisker plots to view distribution of many variables split by target value. Figure 3.3 shows the distribution of other features in our dataset split by target value.\n\n\n\n\n\nFigure 3.3: A 4x2 grid of box-and-whisker plots to speed up EDA ingestion. There are a few features that appear to show differing distributions between target values, such as level of chest pain and resting BP.\n\n\n\n\nViewing a grid of box-and-whisker plots allows us to quickly review the distributions for each target value for each feature specified. There appears to be a few features that have differing distributions, such as chestpain, restingBP, and fastingbloodsugar. Clearly delineated differences between target values will be useful for our logistic regression model in identifying patients with heart disease.\nUsing the information from Figure 3.3, we can create a scatterplot to explore more in-depth the relationship between these features with differing distributions. Below in Figure 3.4, we show a 1x2 grid scatterplot. The left hand panel is maxheartrate by serumcholestrol and the right hand panel is restingBP by serumcholestrol.\n\n\n\n\n\nFigure 3.4: Scatterplots showing 2 quantitative variables, colored by target and symbolized by gender. The left hand panel shows maxheartrate by serumcholestrol and the right hand panel shows restingBP by serumcholestrol.\n\n\n\n\nLooking at the left hand panel, we see that most of the 1 target values (heart disease) are either 0-100 or above 380ish. Most 0 values fall between 150-350ish on serumcholestrol. There does not appear to be any significant differenec between genders as they both appear to be intermixed fairly well. For the right hand panel, we see a more delineated difference for restingBP. There appears to be very few 0 values in the range of 140-200 restingBP. As well, Those above 140 restingBP and above 350 serumcholestrol appear to have a higher concentration of 1 target values. Additionally, there appears to be more males within the range of 140-180 restingBP who have target value of 1 whereas females who have a target value of 1 have a higher restingBP, more towards the range of 180-200 restingBP.\nTo explore the relationship of presence of heart disease and chestpain and noofmajorvessels, we can use countplots split by target value for each resepective level of chestpain and noofmajorvessels.\n\n\n\n\n\nFigure 3.5: A 1x2 grid of countplots. The left hand panel shows the counts for each bucket of chestpain split by target value. The right hand panel shows the counts for each bucket of noofmajorvessels split by target value.\n\n\n\n\nIn the left hand panel of Figure 3.5, we see that as the level of chest pain increases, the proportion of those who have heart disease increase. Additionally, in the right hand panel, as we increase in noofmajorvessels, there is a greater proprotion of those who have heart disease.\n\n\nVerify Model Assumptions\nIn order to properly model this data using logistic regression, we need to verify a few assumptions. First, we need to verify that our observations are independent of one another, that is that no observation mathematically influences any other observation. Thinking logically, we can verify this assumption that someone’s restingBP does not affect any other restingBP, and so forth for every feature found in the dataset. Therefore, we can model our dataset as shown in Equation 4.1.\n\\[\nX_1, ... ,X_n \\sim \\text{ i.i.d. Bernoulli(p)}\n\\tag{4.1}\\]\nThe second assumption we should verify is that of multicollinearity. Multicollinearity occurs when features of a dataset are highly correlated with one another. This results in variance inflation which throws off the standard errors used in statistical modeling calculations. Below are the respective VIF scores for each feature in the dataset.\n\n\n    vif_factor           features\n0     7.407596                age\n1     4.817933             gender\n2     2.769973          chestpain\n3    19.558195          restingBP\n4     6.841284    serumcholestrol\n5     1.631514  fastingbloodsugar\n6     2.275207    restingrelectro\n7    15.313735       maxheartrate\n8     1.957391      exerciseangia\n9     4.107705            oldpeak\n10    6.588688              slope\n11    3.622189   noofmajorvessels\n\n\nA general rule of thumb is that VIF scores above 10 should be eliminated. Therefore, we will remove restingBP and maxheartrate from the dataset in order to verify the assumption of multicollinearity.\n\n\n   vif_factor           features\n0    5.686277                age\n1    4.227614             gender\n2    2.769430          chestpain\n3    5.649147    serumcholestrol\n4    1.629010  fastingbloodsugar\n5    2.247908    restingrelectro\n6    1.883431      exerciseangia\n7    4.075928            oldpeak\n8    6.053960              slope\n9    3.597850   noofmajorvessels\n\n\nAs we can see above in the new VIF scores, none of the scores are above 10 so we will accept these features as passed for the multicollinearity assumption.\nThe last assumption we will verify for our logistic regression model is the linearity assumption, or better said, the monotonicity assumption. We assume that each feature has a monotonic relationship with the target (response) variable. Below, we view this relationship in Figure 4.1\n\n\n\n\n\nFigure 4.1: A 2x5 grid of logistic regression plots, modeling the relationship between a given feature and the target variable. Each feature should have an approximate monotonic relationship with the target variable in order to verify the assumption of monotonicity.\n\n\n\n\nFrom Figure 4.1, we see that each plot demonstrates a monotonic-esque relationship. Therefore, we can verify the monotonicity assumption.\n\n\nModel Creation\nUsing Equation 4.1, we can model our data using the logit function to create a linear relationship with the betas and features and the log-odds of the data. This relationship is shown in Equation 5.1.\n\\[\n\\text{log}(\\frac{p(X)}{1-p(X)}) = \\beta_0 + \\beta_1x_1 ... + \\beta_px_p\n\\tag{5.1}\\]\nAfter fitting Equation 5.1 to our data, we obtain the below results.\n\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                 target   No. Observations:                  750\nModel:                            GLM   Df Residuals:                      739\nModel Family:                Binomial   Df Model:                           10\nLink Function:                  Logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -78.442\nDate:                Fri, 12 Jan 2024   Deviance:                       156.88\nTime:                        12:38:31   Pearson chi2:                     349.\nNo. Iterations:                     9   Pseudo R-squ. (CS):             0.6830\nCovariance Type:            nonrobust                                         \n=====================================================================================\n                        coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------------\nconst               -10.4812      1.364     -7.682      0.000     -13.156      -7.807\nage                  -0.0008      0.012     -0.066      0.947      -0.025       0.023\ngender                2.4959      0.565      4.418      0.000       1.389       3.603\nchestpain             1.2328      0.255      4.836      0.000       0.733       1.733\nserumcholestrol       0.0012      0.002      0.696      0.487      -0.002       0.004\nfastingbloodsugar     0.8571      0.506      1.695      0.090      -0.134       1.848\nrestingrelectro       1.2382      0.316      3.920      0.000       0.619       1.857\nexerciseangia        -0.3699      0.435     -0.849      0.396      -1.223       0.484\noldpeak              -1.1640      0.208     -5.589      0.000      -1.572      -0.756\nslope                 7.1061      0.840      8.460      0.000       5.460       8.752\nnoofmajorvessels      0.1789      0.232      0.770      0.441      -0.276       0.634\n=====================================================================================\n\n\nIn the results above, of the features in the dataset fitted to the model, 5 of them are statistically significant (gender, chestpain, restingelectro, oldpeak, and slope). Of those 5 stat sig. features, only 1 of them has an average negative log-odds effect on classification of heart-disease (oldpeak).\nWhile viewing these betas in their log-odds form is helpful to indicate whether a feature positively or negatively influence the classification of heart-disease, transforming these values into probabilities may be easier to interpret. Below, we transform the betas to probabilities.\n\n\nconst                0.000028\nage                  0.499799\ngender               0.923852\nchestpain            0.774311\nserumcholestrol      0.500289\nfastingbloodsugar    0.702057\nrestingrelectro      0.775258\nexerciseangia        0.408566\noldpeak              0.237940\nslope                0.999181\nnoofmajorvessels     0.544604\ndtype: float64\n\n\nFor example, on average, an increase of 1 in slope results in a .99 factor increase of having heart disease, holding all else constant. It appears that slope and gender have the highest probability factor increase in having heart disease. Let us use these factors to see what the model would predict for the following mock data set: male, age 25, no chest pain, 100 serum cholestrol, 0 fasting blood sugar, resting electro 0, exerciseangia 0, oldpeak 1, slope 0, and noofmajorvessels 0.\n\n\nLog-odds:  0.000117\nOdds-ratio:  1.000117\nProbability:  0.500029\n\n\nThe results above show that our model precicts, on average, that a person with the above characteristics would have an odds-ratio of about 1, or a probability of about 50% of having heart disease. Some may be confused by this result, as the above parameters show increases in probability that should result in a value closer than 1 for an additive model. However, one must remember that it is an additive model by logit (see Equation 5.1). To obtain probabilities, we have to inverse the logit function to isolate \\(p(X)\\), as shown in Equation 5.2.\n\\[\np(X) = \\frac{e^{\\beta_0 + \\beta_1x_1 ... + \\beta_px_p}}{1 + e^{\\beta_0 + \\beta_1x_1 ... + \\beta_px_p}}\n\\tag{5.2}\\]\n\n\nModel Assessment\nAs shown above, our logistic regression model now has predictive capabilties after being fit to the data. In order to gather a general idea of how well it does on testing data, we will perform a validation test set approach, where we withhold 25% of the data to be our test set and 75% of our data will be used as training data for the model. Afterwards, we can evaluate the predictive capability of our model by assessing its roc curve and auc score. These can be found in Figure 6.1\n\n\n\n\n\nFigure 6.1: ROC curve showing how the logistic regression model performed on the test set, with corresponding auc score in bottom right-hand corner of plot.\n\n\n\n\nOur ROC curve in Figure 6.1 shows a nice elbow feature, indicating that our model performs very well at indicating true positives. In addition, our AUC score of .99 shows that our model performs very well at distinguishing between the true positives and false positives, meaning we have very good predictive performance in our logistic regression model. Using these metrics, we can find the optimal classification threshold that maximizes the true positive rate and minimizes that false positive rate. Below is our optimal threshold.\n\n\n0.6519052347690012\n\n\nOur optimal threshold of approximately .65 indicates that we would classify anyone with a probability of heart disease above 65% as 1 (having heart disease) and anyone below 65% probability will be classified as 0 (no heart disease). We can use this value on our test set to create a confusion matrix and see the exact number of true positives and false positives. We can then utilize those numbers to calculate other metrics for model assessment such as sensitivity and specificity. The confusion matrix is found in Figure 6.2.\n\n\n\n\n\nFigure 6.2: Confusion matrix for our logistic regression model. The y axis indicates the true labels of the data and the x axis indicate the predicted label from our model.\n\n\n\n\nAs we can see in the confusion matrix, our model does a great job at predicting true positives and true negatives. The model only mispredicted 1 true negative (generated 1 false negative) and mispredicted 7 true positives (generated 7 false positives). As mentioned above, we can use these numbers to view just how well our model does at identifying true positives and true negatives. Below are the metrics we calculated.\n\n\nAccuracy:  0.968\nSensitivity:  0.9507\nSpecificity:  0.9907\nPPV:  0.9926\nNPV:  0.9386\n\n\nAs shown above, even in our inbalanced data set, we achieved an accuracy of about 97%. Additionally, our sensitivity shows our model is very good at identifying true positives, scoring about 95%. Our specificity score was even better, scoring a 99%, meaning our model is almost perfect at identifying those who do not have the disease (true negatives). Positive predictive value and negative predictive value also prove to be very good, with 99% and 93% respectively. For PPV, this means the probability someone has the disease, given that they tested positive (classified as a 1), is 99%. For NPV, this means the probability someone doesn’t have the disease, given they tested negative (classified as a 0), is 93%.\nThis numbers, when we take into account our threshold value (.65), makes sense since we classify people with heart disease if and only if they are above 65% probability. Otherwise, they are classified as not having heart disease. For reference on how we calculated the above values, see Equation 6.1.\n\\[\nSensitivity = \\frac{TP}{TP+FN}\n\\]\n\\[\nSpecificity = \\frac{TN}{TN+FP}\n\\]\n\\[\nPPV = \\frac{TP}{TP+FP}\n\\]\n\\[\nNPV = \\frac{TN}{TN+FN}\n\\tag{6.1}\\]\n\n\nBayesian Model Creation"
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html",
    "href": "posts/stat_692_proj/hotel_analysis_final.html",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "",
    "text": "TA-MU Hotels is a small, privately owned hotel business. Currently, TA-MU Hotels owns two hotels: One in the heart of Manhattan, NYC and another in Cancun, Mexico. TA-MU Hotels is looking to grow its business and hired us (TheBayesianBandit LLC) to look into how their respective hotels are performing. Specifically, our goal is to generate more profit for TA-MU Hotels by identifying profitable opportunities from their hotel booking data."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#revenue-generation",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#revenue-generation",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Revenue Generation",
    "text": "Revenue Generation\nAs noted in the introduction, TA-MU Hotels currently has two operating hotels. Figure 3.1 shows the current revenue generation by TA-MU Hotels on a daily level. The top panel indicates the total revenue of both hotels while the bottom panel shows the amount of revenue generated by each hotel.\n\n\n\n\n\nFigure 3.1: Time series plot of daily revenue generation of TA-MU Hotels. Top panel shows combined revenue whereas bottom panel shows revenue split by hotel location.\n\n\n\n\nFigure 3.1 shows a general trend of increasing revenue for the company. There also appears to be indications of seasonality in the total company revenue as revenue slows during the winter months and rises again in the spring and summer. Viewing the revenue splits by hotel types, generally the city hotel generates more revenue throughout the year. The resort hotel appears to have large spikes in revenue during the holiday season (December-January). In general, revenue for TA-MU Hotels appears to be gradually increasing over time.\nWhile the city hotel generally brings in the most revenue per day, Figure 3.2 shows that the resort hotel during peak times has more money generated per guest. There appears to be a recurring trend of high spending guests between the months of July-September at the resort hotel.\n\n\n\n\n\nFigure 3.2: Time series plot of average revenue per guest on a daily scale.\n\n\n\n\nWhile Figure 3.1 and Figure 3.2 show the daily revenue generation, we were also curious to see if the amount of money spent by guests differed by their respective length of stay. Figure 3.3 breaks down the average amount of money spent per night by the length of stay for each booking.\n\n\n\n\n\nFigure 3.3: Box plot of average amount of revenue spent per night stay.\n\n\n\n\nFrom Figure 3.3, we see that there is no major difference between the average amount of money spent per night by the length of stay. Customers who only stay one night spend about the same on average per night as those who stay three nights. This result is again seen in Figure 3.4 when we take at each hotel’s average customer expenditure per night.\n\n\n\n\n\nFigure 3.4: Box plot of average amount of revenue spent per night stay by each hotel."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#client-demographics",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#client-demographics",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Client Demographics",
    "text": "Client Demographics\nIdentifying who are our clients generating revenue for our business is the first step in understanding how we strategize to generate more revenue. Figure 3.5 shows the daily average number of people per booking at each hotel.\n\n\n\n\n\nFigure 3.5: Time series plot of average number of people per booking, split by hotel type.\n\n\n\n\nIt appears that on average, the lines for both hotels hover mostly in the two people per booking area. There are a few highs and lows indicating that the average at times could be close to one guest per booking or three guests per booking. Table 3.1 goes into more detail by looking into specific demographic details and the percent of bookings each demographic represents.\n\n\nTable 3.1: Client Demographics\n\n\n\n\n\n\n\n\n\nHotel\nNumber of Adults\nKids in Booking\nCustomer Type\n% Bookings\n\n\n\n\nCity Hotel\n2\nNo\nTransient\n33%\n\n\nResort Hotel\n2\nNo\nTransient\n18%\n\n\nCity Hotel\n2\nNo\nTransient-Party\n10%\n\n\nCity Hotel\n1\nNo\nTransient\n9%\n\n\nResort Hotel\n2\nNo\nTransient-Party\n4%\n\n\n\n\nTable 3.1 shows the top five demographics based on percent of bookings. From the table, we see that our biggest client demographic is two adults of customer type transient (when the booking is not part of a group or contract and is not associated with another transient booking) and no kids in the booking. Both the city hotel and resort hotel have this demographic as their most popular client demographic, with over 50% of total company bookings from this demographic alone. Additionally, in 3rd and 5th place respectively are two adult parties as well but of transient party (booked with a connection to at least one other transient booking)."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#lost-revenue",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#lost-revenue",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Lost Revenue",
    "text": "Lost Revenue\nImportant Note: For the column “is_canceled”, it is a binary classification for canceled = 1 and not canceled = 0.\nNow that we have identified TA-MU Hotels’ current revenue generation trends and their primary clients, we will identify areas of improvement based on lost revenue. Lost revenue primarily comes from canceled bookings. We see in Figure 3.6 that the city hotel, while generating the most bookings overall, also has a larger proportion of canceled bookings than the resort hotel.\n\n\n\n\n\nFigure 3.6: Bar plot of number of not-canceled/canceled bookings broken up by hotel type.\n\n\n\n\nIn order to quantify the impact of these cancelations, Figure 3.7 shows the daily gain of non-canceled bookings vs the daily loss of canceled bookings for each hotel.\n\n\n\n\n\nFigure 3.7: Top panel shows time series plot of daily revenue gained vs daily revenue lost based on non-canceled/canceled bookings in city hotel. Bottom panel shows time series plot of daily revenue gained vs daily revenue lost based on non-canceled/canceled bookings in resort hotel.\n\n\n\n\nAs we can see in Figure 3.7, the city hotel has quite a few times where lost revenue overtakes revenue gained. Several times we see large spikes in canceled bookings and subsequently large spikes in lost revenue. In contrast, it appears the resort hotel rarely has any days where lost revenue overtakes revenue gained. To further dive into the details of all this lost revenue, we can view Table 3.2 to see how many cancelations occur from our top five client demographics.\n\n\nTable 3.2: Client Demographics w/ Cancelations\n\n\n\n\n\n\n\n\n\n\nHotel\nNumber of Adults\nKids in Booking\nCustomer Type\n% Bookings\n% Bookings Canceled\n\n\n\n\nCity Hotel\n2\nNo\nTransient\n33%\n48%\n\n\nResort Hotel\n2\nNo\nTransient\n18%\n33%\n\n\nCity Hotel\n2\nNo\nTransient-Party\n10%\n32%\n\n\nCity Hotel\n1\nNo\nTransient\n9%\n42%\n\n\nResort Hotel\n2\nNo\nTransient-Party\n4%\n22%\n\n\n\n\nTable 3.2 reveals a troubling finding for our top five client demographics. Our number one demographic currently has canceled about 48% of bookings! Our number two demographic, of the same type but at the resort hotel, also boasts a very high 33% canceled bookings. Identifying the reasons behind these cancelations are paramount in helping TA-MU Hotels increase their profitability."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#canceled-bookings-detail",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#canceled-bookings-detail",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Canceled Bookings Detail",
    "text": "Canceled Bookings Detail\nTo further investigate the reasons behind these cancelations for our top demographics, we first investigate the relationship between lead time (time from when booking first entered system to arrival date) and cancelations. Figure 3.8 shows the average lead time between non-canceled bookings and canceled bookings (split by hotel type).\n\n\n\n\n\nFigure 3.8: Bar plot of average lead time split by hotel type and booking status\n\n\n\n\nFrom Figure 3.8, we see that there is a large discrepancy between average lead time between non-canceled and canceled bookings. Particulary, in the city hotel, the canceled bookings nearly have double the lead time on average compared to non-canceled bookings. To further dive into the details of the relationship between canceled bookings and lead time, Figure 3.9 shows the average lead time broken down by how the booking was created (through what marketing channel) split by hotel type and booking status.\n\n\n\n\n\nFigure 3.9: Bar plot of average lead time split by hotel type, distribution channel, and booking status.\n\n\n\n\nThe barplots marked with 0s are bookings that were non-canceled and the barplots with 1s are bookings that were canceled (ie (City Hotel, 0) is average lead time for bookings that were not canceled). As we can see there are still large discrepancies between not canceled and canceled bookings, especially for the city hotel. The TA/TO distribution channel appears to generate the largest lead times for canceled bookings in both the city hotel and the resort hotel."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#target-market",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#target-market",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Target Market",
    "text": "Target Market\nAs noted in Table 3.2 and Table 3.1, over 50% of TA-MU bookings are generated by a single demographic: two adults, transient, no kids. To help TA-MU Hotels become more profitable, we propose that we priortize this demographic for the remainder of the report with the goal of minimizing the effects of canceled bookings and maximizing profits from this primary demographic.\nTo confirm our findings from the canceled bookings detail section, we run the same analyses performed in that section but just on our focused demographic. Figure 4.1 shows the average lead time split by hotel type for non-canceled and canceled bookings, focused on our primary demographic.\n\n\n\n\n\nFigure 4.1: Bar plot of average lead time split by hotel type and booking status.\n\n\n\n\nAs we can see in Figure 4.1, we confirm that the discrepancies between lead time of non-canceled and canceled bookings exist for our primary demographic. To get a further detailed view of where our primary demographic cancels their bookings, we plot in Figure 4.2 the percent of canceled bookings split by distribution channel and hotel type.\n\n\n\n\n\nFigure 4.2: Bar plot of % bookings canceled split by hotel type and marketin distribution channel.\n\n\n\n\nIt appears that for our primary demographic (two adults, transient, no kids in booking), the highest percentage of cancellations for the city hotel are bookings made through the TA/TO channel. For the resort hotel, the highest percentage of cancellations are bookings made through the corporate channel."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#data-setup",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#data-setup",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Data Setup",
    "text": "Data Setup\nWe begin the process of creating a good predictive model by ensuring that the data we feed the model is accurate and useful. To do this, we dropped irrelevant columns to our analysis and filter it to include only data pertaining to our primary demographic. Additionally, we create dummy variable columns in order to account for factors in our model (i.e. distribution channel). The result of our data cleaning and feature engineering is a change from raw data of 119390 rows of data and 37 columns to training data of 61024 rows and 24 columns of data.\nTo help our model more accurately predict cancelations, we use a standard scaler to standardize each column of data. This will help the model recognize each feature as a normally distributed variable. Furthermore, to help determine the predictive capability of our model, we use a train-test split of 75% training and 25% test data. This allocation is randomly done by the train_test_split function provided in scikit-learn."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#model-selection",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#model-selection",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Model Selection",
    "text": "Model Selection\nIn order to determine whether or not we should use the full dataset of 24 features for our model or if a subset of these features would be adequate, we perform forward stepwise selection using a logistic regression model. The results of our model selection procedure are found below.\n\n\nIndex(['lead_time', 'stays_in_weekend_nights', 'previous_cancellations',\n       'previous_bookings_not_canceled', 'booking_changes',\n       'required_car_parking_spaces', 'distribution_channel_TA/TO',\n       'reserved_room_type_E', 'deposit_type_Non Refund',\n       'deposit_type_Refundable', 'hotel_Resort Hotel'],\n      dtype='object')\n\n\nThese 11 features, according to forward stepwise selection, are the features that provide the greatest additional improvement to the model. To test this theory, we compared a logistic regression model with these 11 features against a logistic regression model with all 24 features. The results show that the models performed equally as well at predictive accuracy (both around 75%). We determine that using less features is more computationally efficient for similar predictive accuracy so we will use the 11 features that we found with the forward stepwise selection for the remainder of the iterative process of building a predictive model.\n\nAdditional Features\nAs noted previously in the report, there could be interactions between some of these features. For example, the effect that lead time has on the probability of a cancelation might change based on the kind of distribution channel the lead came from. Therefore, we will add two extra features to current subset of 11 features for our predictive model: interaction between distribution channel and lead time, and interaction between distribution channel and hotel type."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#model-comparisons",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#model-comparisons",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Model Comparisons",
    "text": "Model Comparisons\n\nLogistic Regression\nWe begin with logistic regression to see if this kind of model performs well at predicting cancelations. After fitting our training data to our logistic regression model, we obtainthe following results.\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nis_canceled\nNo. Observations:\n45768\n\n\nModel:\nGLM\nDf Residuals:\n45754\n\n\nModel Family:\nBinomial\nDf Model:\n13\n\n\nLink Function:\nLogit\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-21165.\n\n\nDate:\nThu, 25 Apr 2024\nDeviance:\n42330.\n\n\nTime:\n13:11:47\nPearson chi2:\n3.81e+07\n\n\nNo. Iterations:\n28\nPseudo R-squ. (CS):\n0.3573\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.5268\n3333.240\n0.001\n0.999\n-6530.503\n6535.557\n\n\nx1\n0.5459\n0.016\n33.679\n0.000\n0.514\n0.578\n\n\nx2\n-0.0389\n0.012\n-3.250\n0.001\n-0.062\n-0.015\n\n\nx3\n1.9948\n0.127\n15.751\n0.000\n1.747\n2.243\n\n\nx4\n-0.6542\n0.061\n-10.808\n0.000\n-0.773\n-0.536\n\n\nx5\n-0.1151\n0.013\n-8.943\n0.000\n-0.140\n-0.090\n\n\nx6\n-7.3338\n6598.810\n-0.001\n0.999\n-1.29e+04\n1.29e+04\n\n\nx7\n0.2570\n0.016\n16.150\n0.000\n0.226\n0.288\n\n\nx8\n0.0512\n0.012\n4.387\n0.000\n0.028\n0.074\n\n\nx9\n11.0061\n6281.574\n0.002\n0.999\n-1.23e+04\n1.23e+04\n\n\nx10\n0.4591\n6533.082\n7.03e-05\n1.000\n-1.28e+04\n1.28e+04\n\n\nx11\n-0.0209\n0.013\n-1.658\n0.097\n-0.046\n0.004\n\n\nx12\n0.0620\n0.019\n3.326\n0.001\n0.025\n0.099\n\n\nx13\n-0.0320\n0.013\n-2.467\n0.014\n-0.057\n-0.007\n\n\n\n\n\nFeatures x1, x3, x7, x8, and x12 (lead time, previous cancellations, distribution channel TA/TO, reserved room type E, interaction between lead time and distribution channel TA/TO) show an increase in the log-odds of a cancelation and appear to be statistically significant (alpha = 0.05). Conversely, x2, x4, x5, and x13 (stays in weekend nights, previous bookings not canceled, booking changes, and interaction between distribution channel TA/TO and hotel type) show a decrease in the log-odds of a cancelation.\nUsing this fitted logistic regression model, we can generate predictions and see how the model does at predicting cancelations using our test data. One metric to test the predictive capability of a classification type model is using a ROC curve and computing the AUC score from it. Figure 5.1 shows the corresponding ROC curve and AUC score.\n\n\n\n\n\nFigure 5.1: ROC curve for logistic regression model.\n\n\n\n\nThe ROC curve in Figure 5.1 shows that the model achieves an AUC score of about .82, indicating that the model does a pretty good job at distinguishing between a canceled booking and a non-canceled booking. Using this graph, we can extract the optimal threshold that minimizes our false positive rate while still achieveing a max true positive rate. Using this threshold, we can construct a confusion matrix to gain further inference on how the model performs on discovering cancelations. Figure 5.2 shows the resulting confusion matrix.\n\n\n\n\n\nFigure 5.2: Confusion matrix for logistic regression model.\n\n\n\n\nFrom the confusion matrix, we see that the logistic regression model does a very good job at identifying non-canceled bookings, but does not perform as well at identifying canceled bookings. However, while the performance does drop significantly between canceled and non-canceled booking classification, the majority of the time the model does predict the correct label for canceled bookings. To view more specific metrics from the confusion table, we can view Table 5.1.\n\n\nTable 5.1: Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\nFrom Table 5.1, we see that our logistic regression model performed well in every category except sensitivity. Even then, the sensitivity score is an acceptable one since the majority of the time it correctly labels a cancelation.\n\n\nRandom Forest\nWe now compare a tree based method approach to logistic regression by using a random forest. As we performed above, we will fit a random forest with the same training data and gather predictive metrics (AUC score, confusion matrix metrics) by using the same test set as the logistic regression model. Figure 5.3 shows the ROC curve and corresponding AUC score for the random forest model.\n\n\n\n\n\nFigure 5.3: ROC curve and AUC score for random forest model.\n\n\n\n\nFrom Figure 5.3, we see that the random forest model yielded a worse AUC score than the logistic regression model. We will check the resulting confusion matrix metrics for further comparison. Figure 5.4 contains the confusion matrix and Table 5.2 shows the resulting metrics from the confusion matrix.\n\n\n\n\n\nFigure 5.4: Confusion matrix for random forest model.\n\n\n\n\n\n\nTable 5.2: Random Forest Model vs Logistic Regression Model\n\n\n\n\n(a) Random Forest Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n60%\n\n\nSpecificity\n86%\n\n\nPPV\n76%\n\n\nNPV\n74%\n\n\n\n\n\n\n(b) Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\n\n\nFrom Table 5.2 (a) and comparing these values to Table 5.2 (b), the random forest model performed very similarily to the logistic regression model. The random forest model achieved a higher sensitivity score while dropping in the specificity score. Additionally, the random forest model dropped in PPV but gained in NPV.\n\n\nXGBoost\nSince the random forest model did not appear to beat out the performance of the logistic regression model, we will now perform a comparison between XGBoost classification and the logistic regression model. We will perform the same procedures as done with the logistic regression model and the random forest model. Figure 5.5 shows the resulting ROC curve and corresponding AUC score.\n\n\n\n\n\nFigure 5.5: ROC curve and AUC score for XGBoost model\n\n\n\n\nThe AUC score for the XGBoost model appears to be very similar to the random forest model, and consequently is much lower than the logistic regression model AUC. Figure 5.6 and Table 5.3 show the resulting confusion matrix and corresponding metrics.\n\n\n\n\n\nFigure 5.6: Confusion matrix for XGBoost model.\n\n\n\n\n\n\nTable 5.3: XGBoost vs Logistic Regression Model\n\n\n\n\n(a) XGBoost Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n50%\n\n\nSpecificity\n95%\n\n\nPPV\n88%\n\n\nNPV\n71%\n\n\n\n\n\n\n(b) Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\n\n\nFrom Table 5.3, we see that XGBoost improves in specificity over the logistic regression model, but decreases at almost the same degree in sensitivity. There is also a large jump in PPV and a slight decline in NPV for XGBoost over logistic regression.\n\n\nBayesian Logistic Regression\nThus far we have attempted to compare the logistic regression model to more ensemble-esque methods. We now attempt to demonstrate a different approach to the logistic regression model by incorporating priors on each feature. That is, we will perform a bayesian logistic regression to compare to the normal logistic regression method.\nDue to our limited subject matter expertise in the hotel industry, we will use uninformative priors for each feature. We will assume that each feature is drawn from a normal distribution with mean = \\(\\mu\\) and standard deviation = \\(\\sigma\\). For each \\(\\mu\\), we will place a prior of a normal distribution with \\(\\mu\\) = 0 and \\(\\sigma\\) = 2. For each \\(\\sigma\\), we will place a prior of a inverse gamma distribution with \\(\\alpha\\) = 1 and \\(\\beta\\) = 1.\nFor our sampler, we will use a Hamiltonian Monte Carlo with Energy Conserving Sampling. This is chosen due to the size of our dataset and the lack of sufficient computational power to perform a more precise sampling with sampler such as the No-U Turn sampler. After fitting our bayesian logistic regression model, we obtain the following results in Figure 5.7.\n\n\n\n\n\nFigure 5.7: Posterior distributions for each feature.\n\n\n\n\nA benefit of performing a bayesian model is the viewable uncertainty around parameters of interest. In our case, we can see the distributions of each beta value from our model. For example, the change in log-odds on booking status by lead time is likely to be around .7, but can be anywhere between .65 and .75, according to our model. Additionally, our predictions can also have this kind of uncertainty around them. For example, below is information pertaining to a booking that ended up canceling.\n\n\nlead_time                         110.0\nstays_in_weekend_nights             0.0\nprevious_cancellations              0.0\nprevious_bookings_not_canceled      0.0\nbooking_changes                     0.0\nrequired_car_parking_spaces         0.0\ndistribution_channel_TA/TO          1.0\nreserved_room_type_E                0.0\ndeposit_type_Non Refund             0.0\ndeposit_type_Refundable             0.0\nhotel_Resort Hotel                  0.0\nName: 10000, dtype: float64\n\n\nWe see that there were 110 days between lead entered into system and arrival date, that they were staying in the city hotel (hotel_resort = 0) and that they booked throuh TA/TO. Using our bayesian model, we can view the uncertainty around this prediction, as shown in Figure 5.8.\n\n\n\n\n\nFigure 5.8: Posterior Predictive Distribution for the described canceled booking.\n\n\n\n\nFrom Figure 5.8, we see that the most likely value from the distribution is around .42 to .43. According to the distribution, the probability that somebody with this kind of booking information (from our primary demographic) cancels is around .41 to .44.\nWhile the world of bayesian modeling is fascinating and can be powerful, the goal remains the same of providing a model that could be of use to us in identifying where we need to double book rooms in order to maximize profit for TA-MU Hotels. Just like in the other sections, we will compare the AUC score and derived confusion matrix metrics. Figure 5.9 shows the ROC curve for our bayesian model.\n\n\n\n\n\nFigure 5.9: ROC curve and corresponding AUC score for bayesian logistic regression model.\n\n\n\n\nFrom Figure 5.9, we see that the AUC score is very similar to the original logistic regression model. Figure 5.10 shows the corresponding confusion matrix and Table 5.4 show the comparison between the bayesian logistic regression model and the regular logistic regression model.\n\n\n\n\n\nFigure 5.10: Confusion matrix for bayesian logistic regression model\n\n\n\n\n\n\nTable 5.4: Bayesian Logistic Regression Model vs Logistic Regression Model\n\n\n\n\n(a) Bayesian Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n53%\n\n\nSpecificity\n92%\n\n\nPPV\n84%\n\n\nNPV\n72%\n\n\n\n\n\n\n(b) Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\n\n\nFrom Table 5.4, we see that the two models are very similar. The bayesian model shows a slight increase in specificity and a small decrease in sensitivity. The bayesian model also shows an increase in PPV while keeping NPV the same as the regular logistic regression model."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#model-decision",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#model-decision",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Model Decision",
    "text": "Model Decision\nWhile all 4fourmodels proved to be viable models worthy of use in our system, the two logistic regression models had higher AUC scores and were more balanced in the sensitivity-specificity trade-off. To decide which logistic regression model to use, we look at the confusion matrix metrics and AUC scores. Both models have similar confusion matrix metrics and AUC scores. However, the bayesian logistic regression model has a particular advantage over the regular logistic regression model due to its inherit ability at including uncertainty around parameter estimates and predictions. Therefore, we recommend that we continue with the bayesian logistic regression model as our initial cancelation predictive model.\nThe full model for our bayesian logistic regression model is shown in Equation 5.1\n\\[\n\\text{log}(\\frac{p(Y)}{1-p(Y)}) = \\beta_0 + \\beta_1x_1 ... + \\beta_{m}x_m\n\\]\n\\[\n\\text{Y}_1 ... \\text{Y}_n \\overset{\\text{i.i.d.}}{\\sim} \\text{Bernoulli}(p)\n\\]\n\\[\n\\beta \\sim N(\\mu, \\sigma)\n\\]\n\\[\n\\mu \\sim N(0, 2)\n\\]\n\\[\n\\sigma \\sim IG(1, 1)\n\\tag{5.1}\\]\nEquation 5.1 states that the log-odds of booking status (1 being cancelation and 0 being non-cancelation) is a linear function of \\(m\\) predictors (our 11 features and two interaction terms) weighted by \\(m+1\\) betas (13 for the features and one intercept beta). Our response variable \\(Y\\) is a collection of n number of i.i.d. Bernoulli random variables with probability \\(p\\). Our betas are assumed to be normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). All \\(\\mu\\) values have a normal prior distribution with mean = 0 and standard deviation = 2. All \\(\\sigma\\) values have an inverse gamma prior distribution with shape = 1 and scale = 1."
  },
  {
    "objectID": "posts/welcome/welcome_to_blog.html",
    "href": "posts/welcome/welcome_to_blog.html",
    "title": "Welcome to my blog!",
    "section": "",
    "text": "TL;DR\nThis blog focuses on the use of statistics, particularly bayesian statistics, in the application of business problems. In this post, we review the necessary math background in order to understand future blog posts. As well, we establish expectations for future blog posts and the order in which they are shared.\n\n\nWelcome To My Blog!\nWelcome to my blog! If you are reading this, I hope that means you are as excited about learning statistics as I am about teaching it (and continuing to learn it!). This blog, honestly, is mostly a tool for me to improve my own knowledge in statistics by learning how I would convey it to others. I plan on doing this from a data analysis perspective. Given a certain situation/set of data points, how do we construct the problems we want to solve and implement proper solutions. Particularly, I hope to demonstrate that Bayesian methods can be viable methods to solve problems in business, healthcare, etc. Anyways, I hope you find this blog interesting and useful in your data career. Whether you are just entering data or are an experienced data professional, this blog intends to be a resource in demonstrating good data analysis with sound applied mathematical theory.\n\n\nPrerequisites\nWhile I did mention above that this blog is intended to be useful for beginners and experts alike, I will admit that I will be covering some higher level math, such as:\n\n\nMultivariate Calculus\n\n\nProbability Theory\n\n\nLinear Algebra\n\n\nFor example, suppose we are studying a dataset with a variable that is modeled as an exponential random variable, we would use the below notation to show the probability density function (PDF)\n\\[\\begin{equation}\n\\int_{0}^{\\infty} \\lambda e^{\\lambda x} \\,dx\n\\end{equation}\\]\n\\[\\begin{equation}\nX \\sim Exponential(\\lambda)\n\\end{equation}\\]\nOr, the important Bayes Theorem found below.\n\\[\\begin{equation}\nP(A|B) = \\frac{P(B|A) P(A)}{P(B)}\n\\end{equation}\\]\nDon’t be discourage if the above formulas don’t make sense right now. In each post that these appear, I will breakdown what they mean and their applicability in solving our problem.\n\n\nExpectations\nThe hope of this blog is to present statistics in the form of a data analysis case. For example, let’s say you are a host on AirBnB and want to maximize the number of nights you rent out. How do you properly price your rental given certain parameters (size, geographic setting, etc). We would then present the data points and walk through an analysis of the data by doing the following.\n\n\nExploring the data (EDA) to get to know our dataset\n\n\nConstructing a mathematical framework that can fit our data\n\n\nFit our data to said framework\n\n\nGather inference from our model\n\n\nReview answers explained by our model\n\n\nExplain possible enhancements to our model for future analyses\n\n\nThis will be our attempted framework to blog posts. I hope that by tackling problems in this way, our analytical toolbox will grow and our ability to construct measurable problems from our data will improve. This is the ultimate goal of this blog. I really hope that people will recognize this blog as an opportunity to learn how to think analytically.\n\n\nLet’s do this\nI just want to reiterate that I am excited to learn how to be a better analyst with you by getting to know the math that drives our analytics. I am very passionate about how data can be used to properly drive decision-making in organizations and I hope that this blog motivates you to do the same."
  }
]