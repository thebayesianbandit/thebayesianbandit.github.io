[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Brandon Scott",
    "section": "",
    "text": "I love learning and teaching so this blog is my motivation to learn new topics and learn how to best convey the messages I received. I hope to demonstrate in this blog an analytical way to approach problems. I like using a tool-box method in my posts, approaching a problem and demonstrating how various tools can be used to solve it. I hope you enjoy this blog as much as I enjoy writing it!"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Brandon Scott",
    "section": "Education",
    "text": "Education\nTexas A&M University M.S. in Statistics | January 2023 - May 2024\nUtah Valley University M.S. in Computer Science | September 2021 - April 2022 (transferred)\nBrigham Young University B.S. in Actuarial Science | September 2017 - April 2021"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Brandon Scott",
    "section": "Experience",
    "text": "Experience\nUber | Data Analyst | October 2022 - July 2023 AdvancedMD | Senior Business Analyst | July 2021 - October 2022"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Bayesian Bandit",
    "section": "",
    "text": "An implementation of the ITCC algorithm in Python\n\n\n\npython\n\n\nclustering\n\n\n\n\n\n\n\nBrandon Scott\n\n\nFeb 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAn analysis of Uber fares\n\n\n\nanalysis\n\n\nbayesian\n\n\npython\n\n\n\n\n\n\n\nBrandon Scott\n\n\nJul 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nForecasting Enrollment Size by Class at TAMU\n\n\n\nanalysis\n\n\nbayesian\n\n\npython\n\n\nforecasting\n\n\n\n\n\n\n\nBrandon Scott\n\n\nMay 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAn Analysis of TA-MU Hotel Booking Data\n\n\n\nanalysis\n\n\nbayesian\n\n\npython\n\n\nclassification\n\n\n\n\n\n\n\nBrandon Scott\n\n\nApr 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to my blog!\n\n\n\nwelcome\n\n\nbayesian\n\n\n\n\n\n\n\nBrandon Scott\n\n\nMar 6, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/bayes-pricing/bayesian_pricing_uber.html",
    "href": "posts/bayes-pricing/bayesian_pricing_uber.html",
    "title": "An analysis of Uber fares",
    "section": "",
    "text": "Uber is the current leader in the rideshare market. With millions of people using the platform everyday, the company must prioritize resources to understanding their customer base and how to price their product effectively. This analysis is a simple illustration of the power of bayesian pricing methods for rideshare companies. Specifically, we demonstrate the effectiveness of a basic bayesian linear model at predicting the price of an Uber ride based on our supplied data. Data for this analysis can be found here."
  },
  {
    "objectID": "posts/bayes-pricing/bayesian_pricing_uber.html#investigating-relationships-with-fare-amount",
    "href": "posts/bayes-pricing/bayesian_pricing_uber.html#investigating-relationships-with-fare-amount",
    "title": "An analysis of Uber fares",
    "section": "Investigating Relationships with Fare Amount",
    "text": "Investigating Relationships with Fare Amount\nAs stated earlier, the purpose of this analysis is to analyze what, if anything, have effects on fare amount. We further this exploration in Figure 2.7 where we check the distribution of fare amount by the passenger count.\n\n\n\n\n\nFigure 2.7: Box-and-whisker plots showing the distribution of fare amount by passenger count.\n\n\n\n\nAs we can see, the distributions among passenger count appear to be approximately the same. The median fare amount for each passenger count appears to be constant and each quartile appears to be relatively equal to the others.\nAnother possible influence could be day of the week when a ride is taken. Figure 2.8 shows the respective distributions of fare amount by weekday and weekend.\n\n\n\n\n\nFigure 2.8: Box-and-whisker plot showing distribution of fare amount by weekday vs weekend.\n\n\n\n\nJust as we saw in Figure 2.7, Figure 2.8 shows that there is not much difference between weekday and weekend trips with regard to fare amount.\nAfter having cleaned up our dataset, we can view a scatterplot of trip in miles vs fare amount, colored by weekend or weekday, to see the relationhsip between these variables. This is shown in Figure 2.9.\n\n\n\n\n\nFigure 2.9: Scatterplot of trip in miles vs fare amount, with each dot colored by weekend (orange) and weekday (blue).\n\n\n\n\nEven after our data cleanup, we see in Figure 2.9 that there is a large amount of data to still use. There appears to be a slight positive linear relationship between trip in miles vs fare amount. We will hope to quantify this when we build our model. There also appears to be a lot more rides during the week vs the weekend (which makes sense since there are more weekdays than weekends)."
  },
  {
    "objectID": "posts/bayes-pricing/bayesian_pricing_uber.html#check-for-differences-in-number-of-rides-by-hour",
    "href": "posts/bayes-pricing/bayesian_pricing_uber.html#check-for-differences-in-number-of-rides-by-hour",
    "title": "An analysis of Uber fares",
    "section": "Check for Differences in Number of Rides by Hour",
    "text": "Check for Differences in Number of Rides by Hour\nAs we mentioned at the end of the previous section, there are more rides on weekdays vs weekends. We should continue to explore the difference in these different segments. First, we’ll explore the difference in the number of rides by hour, split by weekdays vs weekends. This is shown in Figure 2.10.\n\n\n\n\n\nFigure 2.10: Top panel shows number of rides by hour on weekdays. Bottom panel shows number of rides by hour on weekends.\n\n\n\n\nAs we can see, although the total number of rides might differ between weekdays and weekends, the trend appears more or less the same. Weekdays have much heavier peaks around the usual rush hour commuting times. Weekends appear to steadily increase from morning to evening.\nWhile weekdays vs weekends are one possible segmentation for number of rides, seasons are also a potential group we should explore for delineations in number of rides. Figure 2.11 shows the number of rides by hour for each season.\n\n\n\n\n\nFigure 2.11: 2x2 grid showing number of rides by hour according to the labeled season.\n\n\n\n\nThere does not appear to be any differences between seasons, except for spring having very low peaks in comparison to the other 3 seasons. Generally speaking, each season follows the same trend of number of rides by hour, with winter, summer, and fall each following very similar trends and numbers."
  },
  {
    "objectID": "posts/bayes-pricing/bayesian_pricing_uber.html#fare-amount-by-time-of-day-and-season",
    "href": "posts/bayes-pricing/bayesian_pricing_uber.html#fare-amount-by-time-of-day-and-season",
    "title": "An analysis of Uber fares",
    "section": "Fare Amount by Time of Day and Season",
    "text": "Fare Amount by Time of Day and Season\nWe return to investigating fare amount since that is the principle objective of this analysis. One relationship we have yet to explore is the fare amount in relation to time of day. To do this, we will bucket each hour into a specific time of day (ie morning) and calculate the distributio of fare prices at that respective time. Figure 2.12 shows this distribution.\n\n\n\n\n\nFigure 2.12: Box-and-whisker plot showing distribution of fare amount by bucketed time of day.\n\n\n\n\nFrom Figure 2.12, we see that there is no real difference in distributions. Dawn appears to have the highest variance of the 5 time buckets, but does not appear to be significant.\nTo combine some of the relationships we have explored thus far, we will look at the change in average fare, split by season and time of day. Perhaps a combination of these segments could show a possible difference in fare price. Figure 2.13 shows this relationship.\n\n\n\n\n\nFigure 2.13: Top panel shows the average fare price and its change over seasons, split by time of day. Bottom panel shows the average fare amount by season, split by weekday vs weekend.\n\n\n\n\nFigure 2.13 is very informative as it shows clear delineations between average fare prices. The top panel shows that dawn by far has the highest average fare price over the other 4 time of day buckets. The closest to each other are evening and afternoon across all seasons. Interestingly, afternoon has a sharp dip in average fare price in the winter. The average afternoon fare price in winter is the lowest, followed closely by morning and evening. While we do notice clear separation between these lines, we should recognize that these prices are within essentially a dollar a part.\nThe bottom panel of Figure 2.13 shows a clear (yet small in dollar value) difference between weekend and non-weekend average fare amounts across seasons. Weekends on average have a higher fare amount than weekdays across all seasons. Additionally, The difference appears constant between the average fare amount of weekends and weekdays across all seasons. Figure 2.13 shows the usefulness of these features in helping the model capture defined segments across the data."
  },
  {
    "objectID": "posts/bayes-pricing/bayesian_pricing_uber.html#simple-prediction-demonstration",
    "href": "posts/bayes-pricing/bayesian_pricing_uber.html#simple-prediction-demonstration",
    "title": "An analysis of Uber fares",
    "section": "Simple Prediction Demonstration",
    "text": "Simple Prediction Demonstration\nTo demonstrate how our model predicts, we will make a prediction for a single passenger, riding 5 miles, in the winter, in the morning, on a weekday. Using our estimated beta distributions above, we obtain the posterior predictive distribution in Figure 3.3.\n\n\n\n\n\nFigure 3.3: Posterior predictive density for a single passenger riding 5 miles in winder during the morning on a weekday.\n\n\n\n\nFrom Figure 3.3, it appears that the average fare amount for a ride like this would be around 20.15 dollars. Approximate 95% PI would be (20.10, 20.20). Our model makes very precise predictions as evident by the short width of the distribution. Nonetheless, this illustrates very well how our bayesian linear model makes a predictive distribution instead of just a single point estimate. We have a small amount of uncertainty around this estimate due to the large amount of training data."
  },
  {
    "objectID": "posts/co_clust_1/co_clustering.html",
    "href": "posts/co_clust_1/co_clustering.html",
    "title": "An implementation of the ITCC algorithm in Python",
    "section": "",
    "text": "Abstract\nClustering is a useful tool in data mining whereby data points are collected together based on some predefined similarity metric. This results in a more digestible data model that can provide solid inference into how related certain attributes of data are with each other. In this post, we discuss the information theoretic co-clustering algorithm (Dhillon, Mallela, and Modha 2003) and provide a python implementation of said algorithm. We discuss the usefulness of co-clustering and propose potential future projects.\nSee this link for the paper.\n\n\nIntroduction\nCo-clustering can be defined as a family of algorithms that simultaneously clusters rows and columns. Suppose we have a matrix A that contains n rows and m columns, as shown below.\n\\[A = \\begin{bmatrix}\n    a_{11} & a_{12} & \\cdots & a_{1m} \\\\\n    a_{21} & a_{22} & \\cdots & a_{2m} \\\\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n    a_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{bmatrix}\\]\nOur objective with \\(A\\) would be to identify distinct groups of data that exhibit great similarities to one another. One way to expose these groupings would be through a clustering algorithm like K-means. However, the down side to K-means is the single modality nature of the algorithm. That is, rows and columns would be clustered independetly of each other. In real-world scenarios, there are generally relationships between the rows and columns that we’d want to capture as part of our analysis. For example, suppose the rows of \\(A\\) were customers and the columns of \\(A\\) were products available. \\(a_{ij}\\) would then represent the quantities purchased by the \\(i\\)th customer for the \\(j\\)th product. We’d want to capture in our analysis the relationships between customers and the products. This is where co-clustering comes in.\nCo-clustering are families of algorithms that simultaneously cluster rows and columns. Contuining with the example above of rows representing customers and columns representing products, suppose we have the following data.\n\\[\\begin{pmatrix}\n    3 & 3 & 0 \\\\\n    4 & 4 & 0 \\\\\n    0 & 0 & 1\n\\end{pmatrix}\\]\n\\(a_{ij}\\) once again represents the purchases by the \\(i\\)th customer for the \\(j\\)th product. In normal clustering approaches (like in K means clustering), we would ignore the column structure of this matrix and instead focus on the row structure only. Thus, we would probably end up with two clusters, with the the first two rows pertaining to one cluster and the last row pertaining to another. This approach, while helpful in identifying data points that closely resemble each other, does not take into account the complete picture offered by the matrix.\nIn co-clustering, we would analyze both the row structure and the column structure. We would continue to use the row structure, as illustrated in the previous example, but we would also include column clusters, more than likely clustering the first two columns together and the last one by itself. Thinking back to what this data set represents, we can now show at a more granular level what customers have similar purchase histories, as well as what products are purchased together. Thus, we have a better understanding of a customer journey and their interactions with our products.\n\n\nInformation Theoretic Co-Clustering\nNow that we have a solid foundation on what co-clustering is and its potential uses, we explore the co-clustering algorithm “Information Theoretic Co-Clustering” (Dhillon, Mallela, and Modha 2003). For a more detailed explanation, please refer to the paper link above or the referenced paper in the works cited.\nThe ITCC algorithm poses the challenge of clustering as an optimization problem using relative entropy, as shown below in Equation 3.1.\n\\[\\begin{equation}\nD_{KL}(P||Q) = \\sum_{x} \\sum_{y} P(x, y) \\log \\left( \\frac{P(x, y)}{Q(x, y)} \\right) \\label{eq:kl_joint_discrete}\n\\end{equation} \\tag{3.1}\\]\nEssentially, we are trying to find a prototype or approximate joint distribution \\(Q(x,y)\\) to minimizes the distance from \\(P(x,y)\\). To do this, the ITCC algorithm attempts to calculate this minimized approximated joint disribution \\(Q(x,y)\\) by monotonically decreasing the objective function (the objective function being mutual information loss, thus minimizing the information lost between the true joint distribution and the approximate joint distribution).\nTo calculate this approximate joint distribution, a set number of row clusters and column clusters are assigned. Then, rows and columns are assigned to a specific cluster number, up to n row clusters and m column clusters. A joint cluster distribution is then calculated, which we will denote as \\(P(\\hat{x},\\hat{y})\\). The approximate joint distribution \\(Q(x,y)\\) is the calculated using \\(P(\\hat{x},\\hat{y}\\) and other conditional distributions. \\(Q(x,y)\\) is calculated by finding rows and columns that minimize Equation 3.1, relative to the conditional \\(P(X|\\hat{Y})\\) and \\(P(Y|\\hat{X})\\). A more structured run through of the algorithm is found below.\n\n\nInitialize co-cluster for rows (\\(C_X\\)) and co-cluster for columns (\\(C_Y\\))\n\n\nCalculate \\(q^{(0)}\\) \\((\\hat{X}, \\hat{Y})\\), \\(q^{(0)}\\) \\((X|\\hat{X})\\), \\(q^{(0)}\\) \\((Y|\\hat{Y})\\), and \\(q^{(0)}\\) \\((Y|\\hat{x})\\)\n\n\nCompute new column clusters for each row x where \\(C^{t+1}_{X}(x)=\\) \\(argmin_{\\hat{x}}\\) \\(D(p(Y|x) || q^{(t)}(Y|\\hat{x}))\\)\n\n\nCompute distributions \\(q^{(t+1)}\\) \\((\\hat{X}, \\hat{Y})\\), \\(q^{(t+1)}\\) \\((X|\\hat{X})\\), \\(q^{(t+1)}\\) \\((Y|\\hat{Y})\\), and \\(q^{(t+1)}\\) \\((X|\\hat{y})\\)\n\n\nCompute new column clusters for each column y where \\(C^{t+2}_{Y}(y)=\\) \\(argmin_{\\hat{y}}\\) \\(D(p(X|y) || q^{(t+1)}(X|\\hat{y}))\\)\n\n\nCompute distributions \\(q^{(t+2)}\\) \\((\\hat{X}, \\hat{Y})\\), \\(q^{(t+2)}\\) \\((X|\\hat{X})\\), \\(q^{(t+2)}\\) \\((Y|\\hat{Y})\\), and \\(q^{(t+2)}\\) \\((Y|\\hat{x})\\)\n\n\nStop and return current row and column clusters (\\(C_X,C_Y\\)) if the change in the objective function value is small. Else, repeat starting at step 2.\n\nEssentially, the algorithm forms row and column cluster prototypes, calculates the appropriate distributions to get to the approximate joint distribution \\(q(X,Y)\\), then measures the distance between \\(p(X,Y)\\) and \\(q(X,Y\\) using Equation 3.1. The algorithm is able to be monotonically decreasing due to the fact that we always select the cluster that minimizes Equation 3.1 (see steps 3 and 5 in the algorithm steps above).\n\n\nCode Walk-Through\nIn this section, we’ll walk through the various code chunks that make up our ITCC algorithm. Full disclosure, this is a very crude approach to implementing this algorithm. There are far better implementations of this algorithm along with other co-clustering algorithms (e.g. scikit learn). This is merely an educational exercise by me to practice implementing clustering algorithms.\nTo begin the code walk through, we will initialize our joint distribution \\(P(X,Y)\\), which is found below. This is the same joint distribution used in the ITCC paper.\n\n#Initialize test array\ntest_arr = np.array([.05, .05, .05, 0, 0, 0, \n          .05, .05, .05, 0, 0, 0, \n          0, 0, 0, .05, .05, .05, \n          0, 0, 0, .05, .05, .05, \n          .04, .04, 0, .04, .04, .04,\n          .04, .04, .04, 0, .04, .04]).reshape(6,6)\n\nOur \\(P(X,Y)\\) is a 6x6 matrix. We will attempt to find the optimal 3 row clusters and 2 columns clusters using our ITCC implementation, just as performed in the ITCC paper. To do this, we will implement various functions that calculate the necessary distributions for eventually comparing \\(P(X,Y)\\) and \\(Q(X,Y)\\).\nOur first function in the code walk through is calculating the joint distribution \\(Q(\\hat{X},\\hat{Y})\\), which is the joint distribution of the row and column clusters. The code to do this is found below.\n\n#Define function for calculating joint distribution\ndef calc_joint(x: dict, y: dict, a: np.array) -&gt; np.array:\n    joint_arr = np.zeros((len(x), len(y)))\n    #joint_arr = {}\n    for i, j in x.items():\n        for z, p in y.items():\n            ind = np.ix_(j,p)\n            joint_arr[i,z] = a[ind].sum()\n    \n    return joint_arr\n\nThe function accepts the row clusters, column clusters, and joint distribution \\(P(X,Y)\\). We chose to use dictionaries to illustrate the structure of co cluster prototypes with the co cluster number as the key and the value being a list of indices where the respective row(s) or column(s) lie. The function returns the mxn array, where m is the number of row clusters and n is the number of columns clusters.\nThe next function we define is \\(Q(X|\\hat{X})\\). This accepts the joint distribution \\(P(X,Y)\\) and the dictionary for the row cluster prototypes. The function then returns a mxn matrix where m is the number of rows in the original matrix (or the total number of rows from all the row clusters) and n is the number of row clusters.\n\n#Define function for calculating conditional of x given x_hat\ndef calc_x_cond(jd: np.array, x_ind: dict) -&gt; np.array:\n    x_mar = jd.sum(axis=1)\n    xhat_mar = calc_x_mar(jd, x_ind)\n    cond_dist = np.zeros((len(x_mar), len(x_ind)))\n    \n    for key, val in x_ind.items():\n        for idx, prb in enumerate(x_mar):\n            if idx in val:\n                cond_dist[idx,key] = prb / xhat_mar[key]\n            else:\n                cond_dist[idx,key] = 0\n    \n    return cond_dist\n\n\\(Q(\\hat{X}|\\hat{Y})\\) is the conditional distribution of the \\(\\hat{X}\\) given \\(\\hat{Y}\\). This just becomes the joint distribution \\(Q(\\hat{X},\\hat{Y})\\) divided by the marginal of \\(Q(\\hat{Y})\\). The function returns a mxn matrix where m is the number of row clusters and n is the number of column clusters.\n\n#Define function for calculation conditional of x_hat given y_hat\ndef calc_xhat_cond(jd: np.array) -&gt; np.array:\n    cond_dist = np.zeros((jd.shape[0], jd.shape[1]))\n    \n    for j in range(jd.shape[1]):\n        y_mar = jd[:,j].sum()\n        for i in range(jd.shape[0]):\n            if y_mar == 0:\n                cond_dist[i,j] = 0\n            else:\n                cond_dist[i,j] = jd[i,j] / y_mar\n    \n    return cond_dist\n\n\\(Q(X|\\hat{Y})\\) is calculated as the product of \\(Q(X|\\hat{X})Q(\\hat{X}|\\hat{Y})\\). This function accepts then the previously calculated \\(Q(X|\\hat{X})\\) distribution and the \\(Q(\\hat{X}|\\hat{Y})\\) distribution. This function returns a mxn matrix where m is the number of rows from the original joint distribution \\(P(X,Y)\\) and n is the the number of columns from the same said distribution.\n\n#Define function for calculating x given y_hat\ndef calc_x_cond_yhat(x_xhat: np.array, xhat_yhat: np.array, x_ind: dict, y_ind: dict) -&gt; np.array:\n    full_arr = []\n    \n    for y_key, y_val in y_ind.items():\n        for _ in range(len(y_val)):\n            row = []\n            for x_key, x_val in x_ind.items():\n                row.extend(xhat_yhat[x_key,y_key] * x_xhat[x_val, x_key])\n            full_arr.append(row)\n            \n    return np.array(full_arr)\n\nWe now arrive at defining the column distributions, first with \\(Q(Y|\\hat{Y})\\). This function accepts the primary joint distribution and the dictionary of \\(\\hat{Y}\\). The function returns a matrix of dimension mxn where m is the number of columns in the original joint distribution and n is the number of column clusters.\n\n#Define function for calculating conditional of y given y_hat\ndef calc_y_cond(jd: np.array, y_ind: dict) -&gt; np.array:\n    y_mar = jd.sum(axis=0)\n    yhat_mar = calc_y_mar(jd, y_ind)\n    cond_dist = np.zeros((len(y_mar), len(y_ind)))\n    \n    for key, val in y_ind.items():\n        for idx, prb in enumerate(y_mar):\n            if idx in val:\n                cond_dist[idx,key] = prb / yhat_mar[key]\n            else:\n                cond_dist[idx,key] = 0\n    \n    return cond_dist\n\n\\(Q(\\hat{Y}|\\hat{X})\\) is calculated very similariy to \\(Q(\\hat{X}|\\hat{Y})\\) and returns, like the previous function, the same dimension of the of the joint co cluster distribution.\n\n#Define function for calculating conditional of y_hat given x_hat\ndef calc_yhat_cond(jd: np.array) -&gt; np.array:\n    cond_dist = np.zeros((jd.shape[0], jd.shape[1]))\n    \n    for i in range(jd.shape[0]):\n        x_mar = jd[i,:].sum()\n        for j in range(jd.shape[1]):\n            if x_mar == 0:\n                cond_dist[i,j] = 0\n            else:\n                cond_dist[i,j] = jd[i,j] / x_mar\n    \n    return cond_dist\n\n\\(Q(Y|\\hat{X})\\) is equal to the product of \\(Q(Y|\\hat{Y}) Q(\\hat{Y}|\\hat{X})\\). This function accepts the \\(Q(Y|\\hat{Y})\\) distribution, \\(Q(\\hat{Y}|\\hat{X})\\) distribution, the column cluster dictionary, and the row cluster dictionary. The function returns a mxn matrix of the same dimension of the original joint distribution.\n\n#Define function for calculating y given x_hat\ndef calc_y_cond_xhat(y_yhat: np.array, yhat_xhat: np.array, y_ind: dict, x_ind: dict) -&gt; np.array:\n    full_arr = []\n    \n    for x_key, x_val in x_ind.items():\n        for _ in range(len(x_val)):\n            row = []\n            for y_key, y_val in y_ind.items():\n                row.extend(yhat_xhat[x_key,y_key] * y_yhat[y_val, y_key])\n            full_arr.append(row)\n            \n    return np.array(full_arr)\n\n\\(C_X\\) represents our current row clusters. The function below takes in the distributions \\(Q(Y|\\hat{X}\\) and \\(P(Y|X)\\), along with the mappings of each row to row to cluster using the x_ind dictionary. This function utilizes Equation 3.1 to find calculate the distance between these distributions. It then selects the cluster row prototype that minimizes the distance between a row of the true distribution and that of the approximate distribution. The function returns a dictionary with the new row cluster prototypes.\n\n#Define function for calculation next c_x\ndef next_cx(y_xhat: np.array, y_x: np.array, x_ind: dict) -&gt; dict:\n    new_x_hat = {key: [] for key in x_ind}\n\n    for i in range(y_x.shape[0]):\n        temp_idx = []\n    \n        for key, val in x_ind.items():\n            proto = np.mean(y_xhat[val,:], axis=0)\n            kl_res = np.nan_to_num(kl_div(y_x[i,:], proto), posinf=10, neginf=-10)\n            #kl_res = rel_entr(y_x[i,:], proto)\n            temp_idx.append(np.sum(kl_res))\n       \n        temp_val = np.argmin(np.array(temp_idx))\n        #temp_val = tie_breaker(temp_idx)\n        new_x_hat[temp_val].append(i)\n    \n    return new_x_hat\n\nSimilarily to the function above \\(C_Y\\) represents our current column clusters. The function utilizes \\(Q(X|\\hat{Y})\\) and \\(P(X|Y)\\) along with the mappings found in y_ind, which contain the mappings of columns to column clusters. It then uses Equation 3.1 to perform the same calculations used in \\(C_X\\). This function also returns a dictionary with the new mappings for column cluster prototypes.\n\n#Define function for calculation next c_y\ndef next_cy(x_yhat: np.array, x_y: np.array, y_ind: dict) -&gt; dict:\n    new_y_hat = {key: [] for key in y_ind}\n\n    for i in range(x_y.shape[1]):\n        temp_idx = []\n\n        for key, val in y_ind.items():\n            proto = np.mean(x_yhat[:,val], axis=1)\n            kl_res = np.nan_to_num(kl_div(x_y[:,i], proto), posinf=10, neginf=-10)\n            #kl_res = rel_entr(x_y[:,i], proto)\n            temp_idx.append(np.sum(kl_res))\n            \n        temp_val = np.argmin(np.array(temp_idx))\n        #temp_val = tie_breaker(temp_idx)\n        new_y_hat[temp_val].append(i)\n       \n    return new_y_hat\n\nThis function is where we formally define the co-clustering algorithm utilizing the functions defined above as well as the steps outline for the ITCC algorithm above. We refer the reader to the above section “Information Theoretic Co-Clustering”. The function accepts the target distribution we wish to perform co-clustering on, as well as the number of row clusters \\(k\\) and column clusters \\(l\\). The user can also specify the number of iterations. The function returns a tuple of form (dict, dict), where the first dictionary is the row cluster and the second is the column cluster.\n\n#Define co-clustering algorithm\ndef co_cluster(joint_dist: np.array, k: int, l: int, num_iter: int) -&gt; (dict, dict):\n    #Initialize x_hat\n    x_hat = get_x_hat(joint_dist, k, new=True)\n    #Initialize y_hat \n    y_hat = get_y_hat(joint_dist, l, new=True)\n    #Initialize min kl val\n    max_kl = .0001\n    print(f\"init_x_hat: {x_hat}, init_y_hat: {y_hat}\")\n    #Enter loop\n    for _ in range(num_iter):\n        \n        #Calculate q(x_hat, y_hat)\n        q_joint_hat = calc_joint(x_hat, y_hat, joint_dist)\n    \n        #Calculate q(x|x_hat)\n        q_x_cond_xhat = calc_x_cond(joint_dist, x_hat)\n        #Calculate q(y|y_hat)\n        q_y_cond_yhat = calc_y_cond(joint_dist, y_hat)\n        #Calculate p(y_hat|x_hat)\n        q_yhat_cond_xhat = calc_yhat_cond(q_joint_hat)\n        \n        #Calculate q(y|x_hat)\n        q_y_cond_xhat = calc_y_cond_xhat(q_y_cond_yhat, q_yhat_cond_xhat, y_hat, x_hat)\n        #Calculate p(y|x)\n        p_y_x = joint_dist / joint_dist.sum(axis=1).reshape(-1,1)\n        \n        #Get next cx\n        x_hat_2 = next_cx(q_y_cond_xhat, p_y_x, x_hat)\n        #Check if x_hat_2 is valid\n        x_hat_2 = valid_cluster(x_hat_2)\n        \n        \n        #Calculate qt+1(x_hat, y_hat)\n        q_joint_hat_2 = calc_joint(x_hat_2, y_hat, joint_dist)\n        \n        #Calculate qt+1(x|x_hat)\n        q_x_cond_xhat_2 = calc_x_cond(joint_dist, x_hat_2)\n        \n        #Calculate qt+1(x_hat|y_hat)\n        q_xhat_cond_yhat_2 = calc_xhat_cond(q_joint_hat_2)\n        \n        #Calculate qt+1(x|y_hat)\n        q_x_cond_yhat = calc_x_cond_yhat(q_x_cond_xhat_2, q_xhat_cond_yhat_2, x_hat_2, y_hat)\n        #Calculate p(x|y)\n        p_x_y = joint_dist / joint_dist.sum(axis=0).reshape(-1,1)\n        \n        #Get next cy\n        y_hat_2 = next_cy(q_x_cond_yhat, p_x_y, y_hat)\n        #Check if y_hat_2 is valid\n        y_hat_2 = valid_cluster(y_hat_2)\n        \n        \n        #Calculate qt+2(x_hat, y_hat)\n        q_joint_hat_3 = calc_joint(x_hat_2, y_hat_2, joint_dist)\n         \n        #Calculate qt+2(y|y_hat)\n        q_y_cond_yhat_2 = calc_y_cond(joint_dist, y_hat_2)\n        \n        #Calculate qt+2(y_hat|x_hat)\n        q_yhat_cond_xhat_2 = calc_yhat_cond(q_joint_hat_3)\n        \n        #Calculate qt+2(y|x_hat)\n        q_y_cond_xhat_2 = calc_y_cond_xhat(q_y_cond_yhat_2, q_yhat_cond_xhat_2, y_hat_2, x_hat_2)\n        \n        #Calculate q(x,y)\n        joint_first = joint_dist.sum(axis=1).reshape(-1,1) * q_y_cond_xhat\n        #Calculate qt+2(x,y)\n        joint_second = joint_dist.sum(axis=1).reshape(-1,1) * q_y_cond_xhat_2\n        \n        \n        kl_res_1 = np.sum(np.nan_to_num(kl_div(joint_dist, joint_first), posinf=10, neginf=-10))\n        kl_res_2 = np.sum(np.nan_to_num(kl_div(joint_dist, joint_second), posinf=10, neginf=-10))\n        \n        kl = kl_res_1 - kl_res_2\n        \n        if kl &gt; max_kl:\n            x_hat = x_hat_2\n            y_hat = y_hat_2\n        else:\n            print(f\"kl={kl} on iteration {_}\")\n            return x_hat, y_hat\n    \n    return x_hat, y_hat\n\n\n\ninit_x_hat: {0: array([0, 3]), 1: array([1, 5]), 2: array([2, 4])}, init_y_hat: {0: array([2, 5, 1]), 1: array([0, 4, 3])}\nkl=0.0 on iteration 2\n\n\n({0: [0, 1], 1: [2, 3], 2: [4, 5]}, {0: [0, 1, 2], 1: [3, 4, 5]})\n\n\nPutting all the pieces together from our code walk through, the output above shows that we have successfully implemented a ITCC algorithm (this utilized the test case from the paper).\n\n\nConclusion\nThough this tutorial was short and consisted of only one test case, we illustrated the usefulness of co-clustering algorithms in a general sense. Additionally, we walked through the steps to implement the information theoretic co-clustering algorithm, along with example code. Further test cases should utilized in production settings. Nonetheless, we hope this post encourages others to discover for themselves the usefulness of co-clustering in their data mining jobs.\n\n\n\n\n\nReferences\n\nDhillon, Inderjit S., Avinash Mallela, and Dharmendra S. Modha. 2003. “Information-Theoretic Co-Clustering.” In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 89–98. ACM."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html",
    "href": "posts/stat_685_proj/final_project.html",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "",
    "text": "Forecasting enrollment for individual classes is important for departments and colleges at universities. It allows them to properly prepare adequate resources for students, such as: hiring the right number of TAs, offering the correct number of sections for classes, and assigning classes to the proper lecture halls. Needless to say, forecasting accurately the number of students signing up for a particular class is of high interest and need. Additionally, if possible, understanding the driving factors behind why certain classes are more popular or which classes are the most variable semester-to-semester is of particular interest.\nWe demonstrate in this post the power of Bayesian forecasting, utilizing a two-part model. The first part forecasts the percent change in enrollment for the upcoming semester compared to the previous semester. The second part forecasts the percent change in percent share of total enrollment at Texas A&M University."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html#feature-engineering-and-data-preprocessing",
    "href": "posts/stat_685_proj/final_project.html#feature-engineering-and-data-preprocessing",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "Feature Engineering and Data Preprocessing",
    "text": "Feature Engineering and Data Preprocessing\nNow that we are somewhat familiar with the data we are working with and the possibilities of how the data can be modeled, we begin compiling the data into one large dataframe. Below is a beginning result of our mergers between dataframes.\n\n\n\n\n\n\n\n\n\nTERM\nCollege\nSubject\nCourse_Number\nis_fall\ncount_students\ncount_freshmen\n\n\n\n\n950\n20213.0\nEN\nENGR\n102.0\nTrue\n4549\n4549\n\n\n2475\n20221.0\nEN\nENGR\n102.0\nFalse\n278\n81\n\n\n4351\n20223.0\nEN\nENGR\n102.0\nTrue\n4993\n4945\n\n\n6583\n20233.0\nEN\nENGR\n102.0\nTrue\n4925\n4869\n\n\n\n\n\n\n\nFrom our sample taken from our newly merged dataframe, we have successfully important data points down to a class and term specific level. We will continue to modify this by adding and removing variables as we see fit. Please refer to the complete code found in the github repo for full information on how the complete data cleaning process was completed."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html#model-1-overall-pct_change-in-enrollment",
    "href": "posts/stat_685_proj/final_project.html#model-1-overall-pct_change-in-enrollment",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "Model 1: Overall pct_change in Enrollment",
    "text": "Model 1: Overall pct_change in Enrollment\n\n\n\n                mean       std    median      5.0%     95.0%     n_eff     r_hat\n        mu      0.02      0.01      0.02      0.00      0.04    682.95      1.00\n     sigma      0.01      0.01      0.01      0.00      0.03    596.88      1.00\n\nNumber of divergences: 62\n\n\nTraining our model on just the percent change between 2021-2022 fall terms, we see our model has shifted the mean of our parameter \\(\\mu\\) from 0.03 to 0.02. Additionally, our sd shrunk as well from 0.02 to 0.01. Our r_hat values of 1.00 and high n_eff scores are good indicators that our model achieved stationarity and good mixing. To continue to confirm that our model has good MCMC diagnostics, we view the trace plots for each of our parameters of interest (see Figure 4.1).\n\n\n\n\n\nFigure 4.1: Trace plots for mu and sigma\n\n\n\n\nFigure 4.1 shows that our sampler mixed well and converged well, as both plots don’t appear to get stuck in any one particular region for too long.\nFigure 4.2 below shows how our prior has been updated using the MAP estimates from our sampler. We see visually what we noticed in the table above, that our posterior became more peaked and shifted left about the x axis.\n\n\n\n\n\nFigure 4.2: Prior and posterior distributions based on MAP values\n\n\n\n\nWhile Figure 4.2 is informative in showing how the MAP values update our prior, the power of Bayesian analysis comes from viewing the entire distribution of each parameter of interest and subsequently using those distributions to provide a predictive distribution, or posterior predictive distribution from which we can gather inference and make forecasts. Below in Figure 4.3 we see the complete distributions for each parameter of interest.\n\n\n\n\n\nFigure 4.3: Posterior distributions of mu and sigma\n\n\n\n\nFigure 4.3 shows that our mu distribution still appears to be approximately normal, centered around 0.02. Our posterior of sigma is less peaked (almost bimodal) but is generally centered around 0.01. Our mu distribution shows that while it is most likely that we have an increase of student enrollment around 2% for this upcoming year, it is within reasonable probability that we could see no increase (eg 0% change). We can use 95% credible intervals to demonstrate what plausible values are within 95% probability for each parameter or interest.\n\n\n95% CI for mu: (-0.001442579022841527, 0.046437517087906624)\n\n\n\n\n95% CI for sigma: (0.0015739109367132187, 0.04049663208425045)\n\n\nOur 95% CI for mu shows that within our 95% probability range, we could possibly see a decrease in student enrollment (be it a small one), but that the majority of our 95% CI includes positive values, meaning we would more than likely see some kind of increase for the next fall term."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html#posterior-predictive-distribution-change-in-enrollment",
    "href": "posts/stat_685_proj/final_project.html#posterior-predictive-distribution-change-in-enrollment",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "Posterior Predictive Distribution (% Change in Enrollment)",
    "text": "Posterior Predictive Distribution (% Change in Enrollment)\nAs mentioned previously, we can now make predictions utilizing our posterior distributions. This is done by integrating out all of our parameters of interest (see Equation 4.1).\n\\[\np(\\overset{\\sim}{y}|y_{1}...y_{n}) = \\int_{\\Theta} p(\\overset{\\sim}{y}|\\theta)p(\\theta|y)\n\\tag{4.1}\\]\nWhat Equation 4.1 says is that in order for us to derive the posterior predictive distribution, integrate across all possible parameters of interest (in our case, mu and sigma) to derive a single distribution, conditioned upon our observed data. Our resulting posterior predictive distribution is found in Figure 4.4.\n\n\n\n\n\nFigure 4.4: Posterior predictive distribution for predicting percent change in enrollment\n\n\n\n\n\n\nMean of PPD: 0.019076179713010788\n\n\n\n\n95% CI of PPD: (-0.023650801740586758 , 0.07064365874975921)\n\n\nOur posterior predictive distribution is centered around 2% still but appears to be a wider distribution. This is because of our wider interval with our sigma distribution. Nonetheless, it is still an approximately normal distribution centered around 2% with corresponding 95% CI (or PI in this case) stating that with 95% probability the percent change in enrollment for the upcoming fall term will be between -2% and 7%. While this interval may be wider than desired, for utilizing only one training point of data and our weakly informative prior, it is a sufficient resource in predicting our fall enrollment for TAMU.\nTo make specific predictions using this distribution, we can utilize the MAP for a point estimate and the 95% CI for a range of predictions. Those results are shown below.\n\n\nBayesian Prediction of Enrollment: 57346\nActual Enrollment: 58933\n\n\n\n\n95% Prediction Interval for Enrollment: (55098, 60158)\n\n\nAs we can see, our Bayesian prediction performed much better than our ARIMA model (granted it was a (0,0,0) model). Additionally, our 95% PI captures the actual value for fall 2023 enrollment at TAMU. As our model continues to receive more data, it will be able to shrink its PI range and have more precise predictions for our forecasts. Nonetheless, we have a viable first model at predicting enrollment at TAMU."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html#more-exploration-for-enhanced-bayesian-modeling",
    "href": "posts/stat_685_proj/final_project.html#more-exploration-for-enhanced-bayesian-modeling",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "More exploration (For enhanced Bayesian Modeling)",
    "text": "More exploration (For enhanced Bayesian Modeling)\nWhile the above model successfully performed better than our “frequentist” approach, it still has not accomplished our ultimate goal of forecasting down to the classroom level. How can we utilize our first model as a viable resource to build a second model that can forecast down to the classroom level?\nThe question to explore now is “do we believe that the percent share of enrollment by class varies or is relatively constant?”. Essentially, if we discover that classes are generally consistent in how much percent of enrollment they take each fall term, then we can build a model that forecasts from our first model and utilizes class specific information to predict its percent share of enrollment. For example, suppose we have an intro level math class that for 3 fall terms had percent share of enrollment of: 2%, 3%, 4%. Utilizing our first model that predicts the entire university enrollment, we can generate a posterior predictive distribution that can predict the percent change in percent share of enrollment and multiply that change in value by the first predicted value (total university enrollment) to get a class specific enrollment value. Equation 4.2 shows the more pretty math behind this intuition.\n\\[\n\\text{class level enrollment} = (\\text{LY } \\% \\text{ enrollment} * (1 + \\% \\text{ change in enrollment})) * (\\text{forecasted enrollment})\n\\tag{4.2}\\]\nBelow is an example table of the data we will utilize to forecast percent share of total enrollment by class.\n\n\n\n\n\n\n\n\n\nSubject\nCourse_Number\nis_fall\nyear\ncount_students\npct_of_enroll\n\n\n\n\n815\nAERS\n101.0\nTrue\n2021\n250\n0.004513\n\n\n5784\nAERS\n101.0\nTrue\n2022\n293\n0.005211\n\n\n8394\nAERS\n101.0\nTrue\n2023\n339\n0.005752\n\n\n821\nAERS\n105.0\nTrue\n2021\n607\n0.010957\n\n\n5790\nAERS\n105.0\nTrue\n2022\n589\n0.010476\n\n\n\n\n\n\n\nWe can build out our formula from Equation 4.2 by creating a new column in our full dataframe to calculate the percent change in percent share of enrollment. Below is an example of this using an intro math class (MATH 140) at TAMU (see last column).\n\n\n\n\n\n\n\n\n\nCollege\nSubject\nCourse_Number\nis_fall\ncount_students\ncount_freshmen\ncount_sophomore\ncount_junior\ncount_senior\ntarget_fresh_adm\n...\ncon_over_target\ncon_over_count_fresh\nyear_adm\ncount\nyr_count\npct_share\npct_class_share\ntotal_enroll\npct_of_enroll\npct_enroll_yoy\n\n\n\n\n107\nAT\nMATH\n140.0\nTrue\n3594\n3190\n294\n72\n38\n2650\n...\n0.953962\n0.792476\n2021\n4158\n16207\n0.256556\n0.196829\n55400\n0.064874\nNaN\n\n\n5049\nAT\nMATH\n140.0\nTrue\n3552\n2975\n412\n114\n51\n2650\n...\n0.909057\n0.809748\n2022\n3924\n15956\n0.245926\n0.186450\n56222\n0.063178\n-0.026136\n\n\n7656\nAT\nMATH\n140.0\nTrue\n4392\n3744\n456\n139\n53\n2650\n...\n0.961887\n0.680823\n2023\n4076\n17415\n0.234051\n0.214987\n58933\n0.074525\n0.179606\n\n\n\n\n3 rows × 26 columns\n\n\n\nAnd another example of an intro aerospace course (AERS 101).\n\n\n\n\n\n\n\n\n\nCollege\nSubject\nCourse_Number\nis_fall\ncount_students\ncount_freshmen\ncount_sophomore\ncount_junior\ncount_senior\ntarget_fresh_adm\n...\ncon_over_target\ncon_over_count_fresh\nyear_adm\ncount\nyr_count\npct_share\npct_class_share\ntotal_enroll\npct_of_enroll\npct_enroll_yoy\n\n\n\n\n815\nEN\nAERS\n101.0\nTrue\n250\n243\n5\n1\n1\n3250\n...\n0.920000\n12.304527\n2021\n4871\n16207\n0.300549\n0.014994\n55400\n0.004513\nNaN\n\n\n5784\nEN\nAERS\n101.0\nTrue\n293\n286\n7\n0\n0\n3250\n...\n1.110154\n12.615385\n2022\n5240\n15956\n0.328403\n0.017924\n56222\n0.005211\n0.154865\n\n\n8394\nEN\nAERS\n101.0\nTrue\n339\n329\n9\n0\n1\n3250\n...\n1.052000\n10.392097\n2023\n5263\n17415\n0.302211\n0.018892\n58933\n0.005752\n0.103773\n\n\n\n\n3 rows × 26 columns\n\n\n\nAnother thing we notice about these classes is an obvious one: they’re different sizes! However, we know that they aren’t all unique in their own size. We can bucket these classes into arbitrary sizes (small, medium, large, etc.) to aid our model in identifying more specifically how certain class sizes vary on their percent change in percent share of enrollment. Below in Figure 4.5 shows a distribution of count of students for classes.\n\n\n\n\n\nFigure 4.5: Histogram of count of students in classes\n\n\n\n\nAs we can see, the great majority of class sizes are found below 1000 students. We will need to take this into account when deciding how to divide our class size lines. While there are different ways of performing this in a more analytical way (i.e. segmentation analysis), we will arbitrarily decide on these buckets based on our EDA (see github repo for full EDA code).\nOne plot that we will include in this post is found in Figure 4.6. This figure shows the distribution for percent change in percent share of enrollment for each of our arbitrarily selected class sizes.\n\n\n\n\n\nFigure 4.6: 2x4 grid of histograms showing the distribution of percent change in percent share of enrollment for each class size\n\n\n\n\nFigure 4.6 is telling in many ways. First, x-small classes are generally non-variable with a few large outliers (this also is acceptable because a x-small class can double in size fairly easily). Small, medium, and large classes are approximately normal in their distribution because these are the class sizes with the most observations (kind of like a fun way of seeing the CLT). All other larger classes appear almost uniform in their distributions due to their small respective sample sizes."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html#model-2-bayesian-hierarchical-model-class-size",
    "href": "posts/stat_685_proj/final_project.html#model-2-bayesian-hierarchical-model-class-size",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "Model 2: Bayesian Hierarchical Model (class size)",
    "text": "Model 2: Bayesian Hierarchical Model (class size)\nAs noted in some of the EDA above, the effects of each class size vary. While they are different, they aren’t completely different (as noted in Figure 4.6). To account for each class size effect individually, we utilize a hierarchical model to allow each class size to pull from a common distribution but to allow their respective effects to take update our prior beliefs. Below is the mathematical representation of our hierarchical model.\n\\[\n\\theta \\sim N(\\mu_{j}, \\sigma_{j})\n\\]\n\\[\n\\mu_{j} \\sim N(0, 0.2)\n\\]\n\\[\n\\sigma_{j} \\sim HN(0.2)\n\\]\nModeling it this way essentially allows our parameter of interest, \\(\\theta\\) to account for between-group variability based on the \\(\\mu_{j}\\) and \\(\\sigma_{j}\\) values while each respective \\(\\mu{j}\\) and \\(\\sigma_{j}\\) accounts for the within-group variability. This kind of flexibility will allow our model to predict down to specific classes based on the corresponding class size. After fitting our model to the data, we obtain the below results.\n\n\n\n                    mean       std    median      5.0%     95.0%     n_eff     r_hat\n   class_mu[0]      0.13      0.02      0.13      0.09      0.17   3864.53      1.00\n   class_mu[1]      0.12      0.02      0.12      0.09      0.16   4569.29      1.00\n   class_mu[2]      0.09      0.01      0.09      0.07      0.12   5660.38      1.00\n   class_mu[3]      0.11      0.02      0.11      0.07      0.15   5829.37      1.00\n   class_mu[4]      0.08      0.04      0.08      0.01      0.15   2455.60      1.00\n   class_mu[5]      0.02      0.02      0.02     -0.01      0.05   3977.78      1.00\n   class_mu[6]     -0.03      0.04     -0.03     -0.09      0.03   1414.55      1.00\n   class_mu[7]      0.01      0.05      0.01     -0.06      0.09   2553.92      1.00\nclass_sigma[0]      1.22      0.02      1.22      1.19      1.25   5456.28      1.00\nclass_sigma[1]      0.55      0.02      0.55      0.53      0.58   2663.55      1.00\nclass_sigma[2]      0.44      0.01      0.44      0.42      0.46   3291.40      1.00\nclass_sigma[3]      0.36      0.02      0.36      0.33      0.38   2453.18      1.00\nclass_sigma[4]      0.24      0.03      0.23      0.19      0.28   2273.90      1.00\nclass_sigma[5]      0.07      0.01      0.07      0.05      0.09   2460.03      1.00\nclass_sigma[6]      0.08      0.04      0.07      0.03      0.13    965.08      1.00\nclass_sigma[7]      0.13      0.05      0.12      0.07      0.19   2506.08      1.00\n            mu      0.05      0.11      0.05     -0.13      0.23   3127.97      1.00\n         sigma      0.37      0.06      0.36      0.27      0.46   2508.96      1.00\n\nNumber of divergences: 0\n\n\nclass_mu[0] represents the distribution for class size x-small while class_mu[7] represents class size giant. All other class sizes are between these ranges in ascending order (x-small to giant). Additionally, our n_eff and r_hat scores show that our sampler performed very well and that each distribution achieved sufficient stationarity and good mixing. To confirm our results using visuals, we can look at Figure 4.7.\n\n\n\n\n\nFigure 4.7: 2x8 trace plots of each class size. Top row are mu trace plots and bottom row are sigma trace plots\n\n\n\n\nFrom Figure 4.7, we see that each mu and sigma trace plot per class appear to have good mixing and acceptable stationarity. Now that we have checked our MCMC diagnostics, we can begin exploring the generated posteriors from our model. Figure 4.8 shows respective distributions for class size’s mu parameter.\n\n\n\n\n\nFigure 4.8: 2x4 grid of posterior distributions for each class size for parameter mu\n\n\n\n\nFigure 4.8 shows each class size mu parameter is approximately normally distributed. It is interesting to note where each distribution is centered. X-small is centered around .13 whereas larger classes like xxx-large are more centered around 0. It appears the there is a higher chance for smaller classes to have an increase in percent change in percent share of enrollment, whereas larger classes don’t vary as much. Larger classes seem to stay most constant term by term, which is not too surprising. A similar plot for class size sigma parameter is found in Figure 4.9.\n\n\n\n\n\nFigure 4.9: 2x4 grid of posterior distributions for each class size for parameter sigma\n\n\n\n\nOnce again, we notice that as the class size increases, the variability in sigma decreases.\n\nPosterior Predictive Distribution (Hierarchical Model)\nJust as we performed in the first model of this analysis, we will generate a posterior predictive distribution to make class specific predictions. Since we built a hierarchical model, we will generate 8 separate PPDs for each class size. Figure 4.10 shows the respective PPD for each class size.\n\n\n\n\n\nFigure 4.10: 2x4 grid of posterior predictive distributions for each class size\n\n\n\n\nFigure 4.10 shows just how variable the smaller classes can be. While the x-small through medium classes are all relatively centered around 0 (possibly due to scale of x axis), the variation in their predictions are fairly wide, especially in x-small classes. However, this should not be too problematic as an x-small class of size 10, even doubling in size, would only be 20. More than likely 1 professor and 1 TA would still be sufficient for this class.\nIn contrast, we see that our larger classes do not have nearly as much predicted variability (a repeated theme we have mentioned a lot). This is good to know since these classes require the most resources. Since they appear to be reliably consistent, we can “trust” more in the predictions and know they will not be too far off from the usual.\nFor example, take the class MATH 140 at TAMU. It is considered an intro level math course that many students must take in order to progress in their respective majors. It is considered a xxx-large class due to its popularity. Below is a point prediction for this class.\n\n\nBayes Prediction for % change in pct_enroll: -0.027\nTrue Value for % change in pct_enroll: 0.180\n\n\nThe model, due to its MAP, incorretly predicted the percent change in percent share of enrollment. However, point estimates in continuous predictions are rarely ever correct and thus require an interval prediction to ensure that our model at least captures the value within the interval. Below is a 95% PI for MATH 140.\n\n\n95% Prediction Interval for % change in pct_enroll: (-0.229, 0.179)\n\n\nAs we can see, our interval would include the actual value (even if it is on the farthest outside). This indicates that the true value that occured is in fact a possibel anomaly. That is, it is a plausible value but is just not very likely. Nonetheless, because we used a Bayesian approach, we can probabilistically say that it is a possible value in the range of 95% probability.\nIn order to properly predict the actual count of student enrollment by class, as mentioned previously, we use Equation 4.2. Below is the predicted number of students, both point estimate and 95% PI.\n\n\nPoint Estimate for MATH 140: 3527\nActual Value for MATH 140: 4392\n\n\n\n\n95% Prediction Interval for MATH 140: (2794, 4271)\n\n\nAs we can see, the 95% prediction interval is not far off from the actual value. The missing values would be trivial in such a large class forecast (at least for allocating university resources). While this test case has been informative, we should test another class to ensure our model is not always facing possible anomalies. To do this, we will look at MATH 308. Below is the point prediction for MATH 308.\n\n\nBayes Prediction for % change in pct_enroll: 0.105\nTrue Value for % change in pct_enroll: 0.051\n\n\nAs we can see, this time our model is over estimating the point estimate for percent change in percent share of enrollment. Our model predicts about a 10% increase in percent share of enrollment when the actual 2023 value was about 5%. While the point estimate is incorrect, it is not too far off in terms of practical prediction. Below is the corresponding 95% PI and resulting predictions from the point estimate and the PI.\n\n\n95% Prediction Interval for % change in pct_enroll: (-0.610, 0.832)\n\n\n\n\nPoint Estimate for MATH 308: 990\nActual Value for MATH 308: 967\n\n\n\n\n95% Prediction Interval for MATH 308: (349, 1640)\n\n\nAs mentioned above, our point estimate from a practical point of view is not too far from the actual value and would not have any major ramifications from a resource allocation point of view. Our 95% PI though, it quite wide. While it is slightly narrower than our 95% PI for MATH 140, it is still a very large range that would not be too useful for forecasting. Nonetheless, this model has proven to be very useful in predicting (especially from a practical point of view) the percent change in percent share of enrollment. Combined with the first model, we have created a system for forecasting class enrollment down to specific class levels."
  },
  {
    "objectID": "posts/stat_685_proj/final_project.html#model-3-bayesian-hierarchical-linear-model-college-and-class-size",
    "href": "posts/stat_685_proj/final_project.html#model-3-bayesian-hierarchical-linear-model-college-and-class-size",
    "title": "Forecasting Enrollment Size by Class at TAMU",
    "section": "Model 3: Bayesian Hierarchical Linear Model (college and class size)",
    "text": "Model 3: Bayesian Hierarchical Linear Model (college and class size)\nWhile our Bayesian hierarchical model proved to be a useful model in our system for forecasting class enrollment, we believe we can do better given the amount of information we have. Another useful piece of information that we can utilize is college. Specifying to which college each class size pertains can help our model distinguish more clearly the percent change in percent share of enrollment for a specific class. Our model will then be an additive model, where we have two covariates (college and class size) predicting our response (% change in % share of enrollment). Below is the mathematical form of our model.\n\\[\nY_{ijk} = X_{ijk}\\beta_{jk} + \\epsilon_{ijk}\n\\]\n\\[\n\\epsilon_{ijk} \\sim N(0, \\sigma^{2})\n\\]\n\\[\nY_{jk} \\sim MVN(X_{jk}\\beta_{jk}, \\sigma^{2}I)\n\\]\n\\[\n\\beta_{j} \\sim N(\\mu_{m},\\sigma_{m}^{2})  \n\\]\n\\[\n\\beta_{k} \\sim N(\\mu_{t}, \\sigma_{t}^{2})\n\\]\n\\[\n\\mu_{m} \\sim N(0, 0.5)\n\\]\n\\[\n\\sigma_{m} \\sim HN(0.5)\n\\]\n\\[\n\\mu_{t} \\sim N(0, 0.5)\n\\]\n\\[\n\\sigma_{t} \\sim HN(0.5)\n\\]\nAfter fitting our model to the data and using a NUTS sampler w/ 500 warmup and 5000 samples, we achieve the below results.\n\n\n\n                     mean       std    median      5.0%     95.0%     n_eff     r_hat\n  class_beta[0]      0.03      0.04      0.03     -0.03      0.10   1825.25      1.00\n  class_beta[1]      0.05      0.04      0.04     -0.01      0.10    688.67      1.00\n  class_beta[2]      0.04      0.03      0.03     -0.01      0.07    752.82      1.00\n  class_beta[3]      0.03      0.02      0.03     -0.01      0.07   1153.19      1.00\n  class_beta[4]      0.03      0.03      0.03     -0.02      0.07   1733.09      1.00\n  class_beta[5]      0.02      0.03      0.02     -0.03      0.07   1545.40      1.00\n  class_beta[6]      0.02      0.03      0.02     -0.03      0.08   1703.07      1.00\n  class_beta[7]      0.02      0.03      0.02     -0.03      0.07   1596.52      1.00\n   class_int[0]      0.03      0.02      0.03     -0.00      0.07    517.34      1.00\n   class_int[1]      0.02      0.02      0.02     -0.01      0.05   1396.59      1.00\n   class_int[2]      0.01      0.02      0.01     -0.02      0.04   2576.21      1.00\n   class_int[3]      0.01      0.02      0.01     -0.02      0.04   2259.81      1.00\n   class_int[4]      0.01      0.02      0.01     -0.02      0.04   2348.81      1.00\n   class_int[5]      0.01      0.02      0.01     -0.02      0.04   2704.20      1.00\n   class_int[6]      0.01      0.02      0.01     -0.02      0.04   2207.97      1.00\n   class_int[7]      0.01      0.02      0.01     -0.02      0.04   1860.08      1.00\ncollege_beta[0]      0.02      0.01      0.02      0.01      0.03    711.33      1.00\ncollege_beta[1]      0.01      0.01      0.01     -0.01      0.03   1322.16      1.00\ncollege_beta[2]      0.00      0.01      0.00     -0.02      0.02    647.16      1.00\ncollege_beta[3]      0.01      0.02      0.01     -0.02      0.03   1262.88      1.00\ncollege_beta[4]      0.00      0.02      0.01     -0.03      0.04   1269.12      1.00\ncollege_beta[5]      0.00      0.03      0.01     -0.04      0.04   1430.99      1.00\ncollege_beta[6]      0.00      0.03      0.01     -0.04      0.05   1733.26      1.00\ncollege_beta[7]      0.00      0.03      0.01     -0.04      0.04   1146.67      1.00\ncollege_beta[8]      0.01      0.03      0.01     -0.03      0.05   2263.37      1.00\ncollege_beta[9]      0.01      0.03      0.01     -0.04      0.04   2195.16      1.00\n       mu_class      0.03      0.02      0.03     -0.01      0.07    844.81      1.00\n     mu_college      0.01      0.01      0.01     -0.02      0.03    915.74      1.00\n         mu_int      0.01      0.01      0.01     -0.00      0.03   1558.78      1.00\n          sigma      0.96      0.01      0.96      0.95      0.98   3696.71      1.00\n    sigma_class      0.03      0.02      0.02      0.00      0.06    456.18      1.00\n  sigma_college      0.02      0.02      0.01      0.00      0.04    407.22      1.00\n      sigma_int      0.01      0.01      0.01      0.00      0.03    348.40      1.00\n\nNumber of divergences: 131\n\n\nOur output for each beta appears to indicate that we have acheived stationarity and good mixing. To verify this visually, we can look at Figure 4.11.\n\n\n\n\n\nFigure 4.11: 2x4 grid of trace plots for each class size\n\n\n\n\nThe betas for each class size level appear to be well mixed and stationary. To verify the betas for each college, we can look at Figure 4.12.\n\n\n\n\n\nFigure 4.12: 2x4 grid of trace plots for each college\n\n\n\n\nJust as with Figure 4.11, we can see that each college appears to have reached appropriate stationarity and mixing. Now that we have verified that our sampler functioned well, we can begin investigating the posterior distributions. Figure 4.13 shows the posterior distributions of each class size and Figure 4.14 shows the posterior distributions for each college.\n\n\n\n\n\nFigure 4.13: Posterior distributions of each class size beta\n\n\n\n\n\n\n\n\n\nFigure 4.14: Posterior distributions of each college beta\n\n\n\n\nIt is interesting to note that in both Figure 4.13 and Figure 4.14, we see that most of the distributions are relatively centered around the point. The distinguishing feature for each distribution is the respective spread.\nJust as we performed for our first hierarchical model, we can perform predictions by generating a posterior predictive distribution (see Equation 4.1). We will first explore the predictions with this model for MATH 308 and compare it to our predictions from our first hierarchical model. The results are shown below.\n\n\nMean of pred_lm: 0.0403\n95% PI of pred_lm: (-0.0108, 0.0907)\nTrue value of pct_enroll_yoy: 0.0507\nPredicted Number of Students: 932\n95% PI of Number of Students: (886, 977)\nTrue Number of Students: 967\n\n\nThe very notable change in our prediction from our hierarchical linear model is that our PI range has shrunk significantly. Instead of the upper limit being close to .8, our upper limit of our 95% PI is approximately .09. That is a significant improvement! Our new hierarchical model also still contains the true value of percent change in percent share of enrollment. As we can see from above, our 95% PI for the predicted number of students is significantly better than before and would be of much better use practically for forecasting. We can perform this exercise again with predictions for MATH 140. Below are our results.\n\n\nMean of pred_lm: 0.0354\n95% PI of pred_lm: (-0.0483, 0.1073)\nTrue value of pct_enroll_yoy: 0.1796\nPredicted Number of Students: 3751\n95% PI of Number of Students: (3448, 4012)\nTrue Number of Students: 4392\n\n\nWe once again see a shrunken PI interval for this class. However, because the true percent change in percent enrollment was a large anomaly, our newly shrunken 95% PI does not capture our true percent change in percent share of enrollment. Nonetheless, the 95% PI can still be of practical use as it is not too far off from the true number of predicted students."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html",
    "href": "posts/stat_692_proj/hotel_analysis_final.html",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "",
    "text": "TA-MU Hotels is a small, privately owned hotel business. Currently, TA-MU Hotels owns two hotels: One in the heart of Manhattan, NYC and another in Cancun, Mexico. TA-MU Hotels is looking to grow its business and hired us (TheBayesianBandit LLC) to look into how their respective hotels are performing. Specifically, our goal is to generate more profit for TA-MU Hotels by identifying profitable opportunities from their hotel booking data."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#revenue-generation",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#revenue-generation",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Revenue Generation",
    "text": "Revenue Generation\nAs noted in the introduction, TA-MU Hotels currently has two operating hotels. Figure 3.1 shows the current revenue generation by TA-MU Hotels on a daily level. The top panel indicates the total revenue of both hotels while the bottom panel shows the amount of revenue generated by each hotel.\n\n\n\n\n\nFigure 3.1: Time series plot of daily revenue generation of TA-MU Hotels. Top panel shows combined revenue whereas bottom panel shows revenue split by hotel location.\n\n\n\n\nFigure 3.1 shows a general trend of increasing revenue for the company. There also appears to be indications of seasonality in the total company revenue as revenue slows during the winter months and rises again in the spring and summer. Viewing the revenue splits by hotel types, generally the city hotel generates more revenue throughout the year. The resort hotel appears to have large spikes in revenue during the holiday season (December-January). In general, revenue for TA-MU Hotels appears to be gradually increasing over time.\nWhile the city hotel generally brings in the most revenue per day, Figure 3.2 shows that the resort hotel during peak times has more money generated per guest. There appears to be a recurring trend of high spending guests between the months of July-September at the resort hotel.\n\n\n\n\n\nFigure 3.2: Time series plot of average revenue per guest on a daily scale.\n\n\n\n\nWhile Figure 3.1 and Figure 3.2 show the daily revenue generation, we were also curious to see if the amount of money spent by guests differed by their respective length of stay. Figure 3.3 breaks down the average amount of money spent per night by the length of stay for each booking.\n\n\n\n\n\nFigure 3.3: Box plot of average amount of revenue spent per night stay.\n\n\n\n\nFrom Figure 3.3, we see that there is no major difference between the average amount of money spent per night by the length of stay. Customers who only stay one night spend about the same on average per night as those who stay three nights. This result is again seen in Figure 3.4 when we take at each hotel’s average customer expenditure per night.\n\n\n\n\n\nFigure 3.4: Box plot of average amount of revenue spent per night stay by each hotel."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#client-demographics",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#client-demographics",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Client Demographics",
    "text": "Client Demographics\nIdentifying who are our clients generating revenue for our business is the first step in understanding how we strategize to generate more revenue. Figure 3.5 shows the daily average number of people per booking at each hotel.\n\n\n\n\n\nFigure 3.5: Time series plot of average number of people per booking, split by hotel type.\n\n\n\n\nIt appears that on average, the lines for both hotels hover mostly in the two people per booking area. There are a few highs and lows indicating that the average at times could be close to one guest per booking or three guests per booking. Table 3.1 goes into more detail by looking into specific demographic details and the percent of bookings each demographic represents.\n\n\nTable 3.1: Client Demographics\n\n\n\n\n\n\n\n\n\nHotel\nNumber of Adults\nKids in Booking\nCustomer Type\n% Bookings\n\n\n\n\nCity Hotel\n2\nNo\nTransient\n33%\n\n\nResort Hotel\n2\nNo\nTransient\n18%\n\n\nCity Hotel\n2\nNo\nTransient-Party\n10%\n\n\nCity Hotel\n1\nNo\nTransient\n9%\n\n\nResort Hotel\n2\nNo\nTransient-Party\n4%\n\n\n\n\nTable 3.1 shows the top five demographics based on percent of bookings. From the table, we see that our biggest client demographic is two adults of customer type transient (when the booking is not part of a group or contract and is not associated with another transient booking) and no kids in the booking. Both the city hotel and resort hotel have this demographic as their most popular client demographic, with over 50% of total company bookings from this demographic alone. Additionally, in 3rd and 5th place respectively are two adult parties as well but of transient party (booked with a connection to at least one other transient booking)."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#lost-revenue",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#lost-revenue",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Lost Revenue",
    "text": "Lost Revenue\nImportant Note: For the column “is_canceled”, it is a binary classification for canceled = 1 and not canceled = 0.\nNow that we have identified TA-MU Hotels’ current revenue generation trends and their primary clients, we will identify areas of improvement based on lost revenue. Lost revenue primarily comes from canceled bookings. We see in Figure 3.6 that the city hotel, while generating the most bookings overall, also has a larger proportion of canceled bookings than the resort hotel.\n\n\n\n\n\nFigure 3.6: Bar plot of number of not-canceled/canceled bookings broken up by hotel type.\n\n\n\n\nIn order to quantify the impact of these cancelations, Figure 3.7 shows the daily gain of non-canceled bookings vs the daily loss of canceled bookings for each hotel.\n\n\n\n\n\nFigure 3.7: Top panel shows time series plot of daily revenue gained vs daily revenue lost based on non-canceled/canceled bookings in city hotel. Bottom panel shows time series plot of daily revenue gained vs daily revenue lost based on non-canceled/canceled bookings in resort hotel.\n\n\n\n\nAs we can see in Figure 3.7, the city hotel has quite a few times where lost revenue overtakes revenue gained. Several times we see large spikes in canceled bookings and subsequently large spikes in lost revenue. In contrast, it appears the resort hotel rarely has any days where lost revenue overtakes revenue gained. To further dive into the details of all this lost revenue, we can view Table 3.2 to see how many cancelations occur from our top five client demographics.\n\n\nTable 3.2: Client Demographics w/ Cancelations\n\n\n\n\n\n\n\n\n\n\nHotel\nNumber of Adults\nKids in Booking\nCustomer Type\n% Bookings\n% Bookings Canceled\n\n\n\n\nCity Hotel\n2\nNo\nTransient\n33%\n48%\n\n\nResort Hotel\n2\nNo\nTransient\n18%\n33%\n\n\nCity Hotel\n2\nNo\nTransient-Party\n10%\n32%\n\n\nCity Hotel\n1\nNo\nTransient\n9%\n42%\n\n\nResort Hotel\n2\nNo\nTransient-Party\n4%\n22%\n\n\n\n\nTable 3.2 reveals a troubling finding for our top five client demographics. Our number one demographic currently has canceled about 48% of bookings! Our number two demographic, of the same type but at the resort hotel, also boasts a very high 33% canceled bookings. Identifying the reasons behind these cancelations are paramount in helping TA-MU Hotels increase their profitability."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#canceled-bookings-detail",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#canceled-bookings-detail",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Canceled Bookings Detail",
    "text": "Canceled Bookings Detail\nTo further investigate the reasons behind these cancelations for our top demographics, we first investigate the relationship between lead time (time from when booking first entered system to arrival date) and cancelations. Figure 3.8 shows the average lead time between non-canceled bookings and canceled bookings (split by hotel type).\n\n\n\n\n\nFigure 3.8: Bar plot of average lead time split by hotel type and booking status\n\n\n\n\nFrom Figure 3.8, we see that there is a large discrepancy between average lead time between non-canceled and canceled bookings. Particulary, in the city hotel, the canceled bookings nearly have double the lead time on average compared to non-canceled bookings. To further dive into the details of the relationship between canceled bookings and lead time, Figure 3.9 shows the average lead time broken down by how the booking was created (through what marketing channel) split by hotel type and booking status.\n\n\n\n\n\nFigure 3.9: Bar plot of average lead time split by hotel type, distribution channel, and booking status.\n\n\n\n\nThe barplots marked with 0s are bookings that were non-canceled and the barplots with 1s are bookings that were canceled (ie (City Hotel, 0) is average lead time for bookings that were not canceled). As we can see there are still large discrepancies between not canceled and canceled bookings, especially for the city hotel. The TA/TO distribution channel appears to generate the largest lead times for canceled bookings in both the city hotel and the resort hotel."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#target-market",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#target-market",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Target Market",
    "text": "Target Market\nAs noted in Table 3.2 and Table 3.1, over 50% of TA-MU bookings are generated by a single demographic: two adults, transient, no kids. To help TA-MU Hotels become more profitable, we propose that we priortize this demographic for the remainder of the report with the goal of minimizing the effects of canceled bookings and maximizing profits from this primary demographic.\nTo confirm our findings from the canceled bookings detail section, we run the same analyses performed in that section but just on our focused demographic. Figure 4.1 shows the average lead time split by hotel type for non-canceled and canceled bookings, focused on our primary demographic.\n\n\n\n\n\nFigure 4.1: Bar plot of average lead time split by hotel type and booking status.\n\n\n\n\nAs we can see in Figure 4.1, we confirm that the discrepancies between lead time of non-canceled and canceled bookings exist for our primary demographic. To get a further detailed view of where our primary demographic cancels their bookings, we plot in Figure 4.2 the percent of canceled bookings split by distribution channel and hotel type.\n\n\n\n\n\nFigure 4.2: Bar plot of % bookings canceled split by hotel type and marketin distribution channel.\n\n\n\n\nIt appears that for our primary demographic (two adults, transient, no kids in booking), the highest percentage of cancellations for the city hotel are bookings made through the TA/TO channel. For the resort hotel, the highest percentage of cancellations are bookings made through the corporate channel."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#data-setup",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#data-setup",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Data Setup",
    "text": "Data Setup\nWe begin the process of creating a good predictive model by ensuring that the data we feed the model is accurate and useful. To do this, we dropped irrelevant columns to our analysis and filter it to include only data pertaining to our primary demographic. Additionally, we create dummy variable columns in order to account for factors in our model (i.e. distribution channel). The result of our data cleaning and feature engineering is a change from raw data of 119390 rows of data and 37 columns to training data of 61024 rows and 24 columns of data.\nTo help our model more accurately predict cancelations, we use a standard scaler to standardize each column of data. This will help the model recognize each feature as a normally distributed variable. Furthermore, to help determine the predictive capability of our model, we use a train-test split of 75% training and 25% test data. This allocation is randomly done by the train_test_split function provided in scikit-learn."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#model-selection",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#model-selection",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Model Selection",
    "text": "Model Selection\nIn order to determine whether or not we should use the full dataset of 24 features for our model or if a subset of these features would be adequate, we perform forward stepwise selection using a logistic regression model. The results of our model selection procedure are found below.\n\n\nIndex(['lead_time', 'stays_in_weekend_nights', 'previous_cancellations',\n       'previous_bookings_not_canceled', 'booking_changes',\n       'required_car_parking_spaces', 'distribution_channel_TA/TO',\n       'reserved_room_type_E', 'deposit_type_Non Refund',\n       'deposit_type_Refundable', 'hotel_Resort Hotel'],\n      dtype='object')\n\n\nThese 11 features, according to forward stepwise selection, are the features that provide the greatest additional improvement to the model. To test this theory, we compared a logistic regression model with these 11 features against a logistic regression model with all 24 features. The results show that the models performed equally as well at predictive accuracy (both around 75%). We determine that using less features is more computationally efficient for similar predictive accuracy so we will use the 11 features that we found with the forward stepwise selection for the remainder of the iterative process of building a predictive model.\n\nAdditional Features\nAs noted previously in the report, there could be interactions between some of these features. For example, the effect that lead time has on the probability of a cancelation might change based on the kind of distribution channel the lead came from. Therefore, we will add two extra features to current subset of 11 features for our predictive model: interaction between distribution channel and lead time, and interaction between distribution channel and hotel type."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#model-comparisons",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#model-comparisons",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Model Comparisons",
    "text": "Model Comparisons\n\nLogistic Regression\nWe begin with logistic regression to see if this kind of model performs well at predicting cancelations. After fitting our training data to our logistic regression model, we obtainthe following results.\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nis_canceled\nNo. Observations:\n45768\n\n\nModel:\nGLM\nDf Residuals:\n45754\n\n\nModel Family:\nBinomial\nDf Model:\n13\n\n\nLink Function:\nLogit\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-21165.\n\n\nDate:\nThu, 25 Apr 2024\nDeviance:\n42330.\n\n\nTime:\n13:11:47\nPearson chi2:\n3.81e+07\n\n\nNo. Iterations:\n28\nPseudo R-squ. (CS):\n0.3573\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.5268\n3333.240\n0.001\n0.999\n-6530.503\n6535.557\n\n\nx1\n0.5459\n0.016\n33.679\n0.000\n0.514\n0.578\n\n\nx2\n-0.0389\n0.012\n-3.250\n0.001\n-0.062\n-0.015\n\n\nx3\n1.9948\n0.127\n15.751\n0.000\n1.747\n2.243\n\n\nx4\n-0.6542\n0.061\n-10.808\n0.000\n-0.773\n-0.536\n\n\nx5\n-0.1151\n0.013\n-8.943\n0.000\n-0.140\n-0.090\n\n\nx6\n-7.3338\n6598.810\n-0.001\n0.999\n-1.29e+04\n1.29e+04\n\n\nx7\n0.2570\n0.016\n16.150\n0.000\n0.226\n0.288\n\n\nx8\n0.0512\n0.012\n4.387\n0.000\n0.028\n0.074\n\n\nx9\n11.0061\n6281.574\n0.002\n0.999\n-1.23e+04\n1.23e+04\n\n\nx10\n0.4591\n6533.082\n7.03e-05\n1.000\n-1.28e+04\n1.28e+04\n\n\nx11\n-0.0209\n0.013\n-1.658\n0.097\n-0.046\n0.004\n\n\nx12\n0.0620\n0.019\n3.326\n0.001\n0.025\n0.099\n\n\nx13\n-0.0320\n0.013\n-2.467\n0.014\n-0.057\n-0.007\n\n\n\n\n\nFeatures x1, x3, x7, x8, and x12 (lead time, previous cancellations, distribution channel TA/TO, reserved room type E, interaction between lead time and distribution channel TA/TO) show an increase in the log-odds of a cancelation and appear to be statistically significant (alpha = 0.05). Conversely, x2, x4, x5, and x13 (stays in weekend nights, previous bookings not canceled, booking changes, and interaction between distribution channel TA/TO and hotel type) show a decrease in the log-odds of a cancelation.\nUsing this fitted logistic regression model, we can generate predictions and see how the model does at predicting cancelations using our test data. One metric to test the predictive capability of a classification type model is using a ROC curve and computing the AUC score from it. Figure 5.1 shows the corresponding ROC curve and AUC score.\n\n\n\n\n\nFigure 5.1: ROC curve for logistic regression model.\n\n\n\n\nThe ROC curve in Figure 5.1 shows that the model achieves an AUC score of about .82, indicating that the model does a pretty good job at distinguishing between a canceled booking and a non-canceled booking. Using this graph, we can extract the optimal threshold that minimizes our false positive rate while still achieveing a max true positive rate. Using this threshold, we can construct a confusion matrix to gain further inference on how the model performs on discovering cancelations. Figure 5.2 shows the resulting confusion matrix.\n\n\n\n\n\nFigure 5.2: Confusion matrix for logistic regression model.\n\n\n\n\nFrom the confusion matrix, we see that the logistic regression model does a very good job at identifying non-canceled bookings, but does not perform as well at identifying canceled bookings. However, while the performance does drop significantly between canceled and non-canceled booking classification, the majority of the time the model does predict the correct label for canceled bookings. To view more specific metrics from the confusion table, we can view Table 5.1.\n\n\nTable 5.1: Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\nFrom Table 5.1, we see that our logistic regression model performed well in every category except sensitivity. Even then, the sensitivity score is an acceptable one since the majority of the time it correctly labels a cancelation.\n\n\nRandom Forest\nWe now compare a tree based method approach to logistic regression by using a random forest. As we performed above, we will fit a random forest with the same training data and gather predictive metrics (AUC score, confusion matrix metrics) by using the same test set as the logistic regression model. Figure 5.3 shows the ROC curve and corresponding AUC score for the random forest model.\n\n\n\n\n\nFigure 5.3: ROC curve and AUC score for random forest model.\n\n\n\n\nFrom Figure 5.3, we see that the random forest model yielded a worse AUC score than the logistic regression model. We will check the resulting confusion matrix metrics for further comparison. Figure 5.4 contains the confusion matrix and Table 5.2 shows the resulting metrics from the confusion matrix.\n\n\n\n\n\nFigure 5.4: Confusion matrix for random forest model.\n\n\n\n\n\n\nTable 5.2: Random Forest Model vs Logistic Regression Model\n\n\n\n\n(a) Random Forest Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n60%\n\n\nSpecificity\n86%\n\n\nPPV\n76%\n\n\nNPV\n74%\n\n\n\n\n\n\n(b) Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\n\n\nFrom Table 5.2 (a) and comparing these values to Table 5.2 (b), the random forest model performed very similarily to the logistic regression model. The random forest model achieved a higher sensitivity score while dropping in the specificity score. Additionally, the random forest model dropped in PPV but gained in NPV.\n\n\nXGBoost\nSince the random forest model did not appear to beat out the performance of the logistic regression model, we will now perform a comparison between XGBoost classification and the logistic regression model. We will perform the same procedures as done with the logistic regression model and the random forest model. Figure 5.5 shows the resulting ROC curve and corresponding AUC score.\n\n\n\n\n\nFigure 5.5: ROC curve and AUC score for XGBoost model\n\n\n\n\nThe AUC score for the XGBoost model appears to be very similar to the random forest model, and consequently is much lower than the logistic regression model AUC. Figure 5.6 and Table 5.3 show the resulting confusion matrix and corresponding metrics.\n\n\n\n\n\nFigure 5.6: Confusion matrix for XGBoost model.\n\n\n\n\n\n\nTable 5.3: XGBoost vs Logistic Regression Model\n\n\n\n\n(a) XGBoost Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n50%\n\n\nSpecificity\n95%\n\n\nPPV\n88%\n\n\nNPV\n71%\n\n\n\n\n\n\n(b) Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\n\n\nFrom Table 5.3, we see that XGBoost improves in specificity over the logistic regression model, but decreases at almost the same degree in sensitivity. There is also a large jump in PPV and a slight decline in NPV for XGBoost over logistic regression.\n\n\nBayesian Logistic Regression\nThus far we have attempted to compare the logistic regression model to more ensemble-esque methods. We now attempt to demonstrate a different approach to the logistic regression model by incorporating priors on each feature. That is, we will perform a bayesian logistic regression to compare to the normal logistic regression method.\nDue to our limited subject matter expertise in the hotel industry, we will use uninformative priors for each feature. We will assume that each feature is drawn from a normal distribution with mean = \\(\\mu\\) and standard deviation = \\(\\sigma\\). For each \\(\\mu\\), we will place a prior of a normal distribution with \\(\\mu\\) = 0 and \\(\\sigma\\) = 2. For each \\(\\sigma\\), we will place a prior of a inverse gamma distribution with \\(\\alpha\\) = 1 and \\(\\beta\\) = 1.\nFor our sampler, we will use a Hamiltonian Monte Carlo with Energy Conserving Sampling. This is chosen due to the size of our dataset and the lack of sufficient computational power to perform a more precise sampling with sampler such as the No-U Turn sampler. After fitting our bayesian logistic regression model, we obtain the following results in Figure 5.7.\n\n\n\n\n\nFigure 5.7: Posterior distributions for each feature.\n\n\n\n\nA benefit of performing a bayesian model is the viewable uncertainty around parameters of interest. In our case, we can see the distributions of each beta value from our model. For example, the change in log-odds on booking status by lead time is likely to be around .7, but can be anywhere between .65 and .75, according to our model. Additionally, our predictions can also have this kind of uncertainty around them. For example, below is information pertaining to a booking that ended up canceling.\n\n\nlead_time                         110.0\nstays_in_weekend_nights             0.0\nprevious_cancellations              0.0\nprevious_bookings_not_canceled      0.0\nbooking_changes                     0.0\nrequired_car_parking_spaces         0.0\ndistribution_channel_TA/TO          1.0\nreserved_room_type_E                0.0\ndeposit_type_Non Refund             0.0\ndeposit_type_Refundable             0.0\nhotel_Resort Hotel                  0.0\nName: 10000, dtype: float64\n\n\nWe see that there were 110 days between lead entered into system and arrival date, that they were staying in the city hotel (hotel_resort = 0) and that they booked throuh TA/TO. Using our bayesian model, we can view the uncertainty around this prediction, as shown in Figure 5.8.\n\n\n\n\n\nFigure 5.8: Posterior Predictive Distribution for the described canceled booking.\n\n\n\n\nFrom Figure 5.8, we see that the most likely value from the distribution is around .42 to .43. According to the distribution, the probability that somebody with this kind of booking information (from our primary demographic) cancels is around .41 to .44.\nWhile the world of bayesian modeling is fascinating and can be powerful, the goal remains the same of providing a model that could be of use to us in identifying where we need to double book rooms in order to maximize profit for TA-MU Hotels. Just like in the other sections, we will compare the AUC score and derived confusion matrix metrics. Figure 5.9 shows the ROC curve for our bayesian model.\n\n\n\n\n\nFigure 5.9: ROC curve and corresponding AUC score for bayesian logistic regression model.\n\n\n\n\nFrom Figure 5.9, we see that the AUC score is very similar to the original logistic regression model. Figure 5.10 shows the corresponding confusion matrix and Table 5.4 show the comparison between the bayesian logistic regression model and the regular logistic regression model.\n\n\n\n\n\nFigure 5.10: Confusion matrix for bayesian logistic regression model\n\n\n\n\n\n\nTable 5.4: Bayesian Logistic Regression Model vs Logistic Regression Model\n\n\n\n\n(a) Bayesian Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n53%\n\n\nSpecificity\n92%\n\n\nPPV\n84%\n\n\nNPV\n72%\n\n\n\n\n\n\n(b) Logistic Regression Metrics\n\n\nMetric Name\nScore\n\n\n\n\nAccuracy\n75%\n\n\nSensitivity\n55%\n\n\nSpecificity\n89%\n\n\nPPV\n80%\n\n\nNPV\n72%\n\n\n\n\n\n\nFrom Table 5.4, we see that the two models are very similar. The bayesian model shows a slight increase in specificity and a small decrease in sensitivity. The bayesian model also shows an increase in PPV while keeping NPV the same as the regular logistic regression model."
  },
  {
    "objectID": "posts/stat_692_proj/hotel_analysis_final.html#model-decision",
    "href": "posts/stat_692_proj/hotel_analysis_final.html#model-decision",
    "title": "An Analysis of TA-MU Hotel Booking Data",
    "section": "Model Decision",
    "text": "Model Decision\nWhile all four models proved to be viable models worthy of use in our system, the two logistic regression models had higher AUC scores and were more balanced in the sensitivity-specificity trade-off. To decide which logistic regression model to use, we look at the confusion matrix metrics and AUC scores. Both models have similar confusion matrix metrics and AUC scores. However, the bayesian logistic regression model has a particular advantage over the regular logistic regression model due to its inherit ability at including uncertainty around parameter estimates and predictions. Therefore, we recommend that we continue with the bayesian logistic regression model as our initial cancelation predictive model.\nThe full model for our bayesian logistic regression model is shown in Equation 5.1\n\\[\n\\text{log}(\\frac{p(Y)}{1-p(Y)}) = \\beta_0 + \\beta_1x_1 ... + \\beta_{m}x_m\n\\]\n\\[\n\\text{Y}_1 ... \\text{Y}_n \\overset{\\text{i.i.d.}}{\\sim} \\text{Bernoulli}(p)\n\\]\n\\[\n\\beta \\sim N(\\mu, \\sigma)\n\\]\n\\[\n\\mu \\sim N(0, 2)\n\\]\n\\[\n\\sigma \\sim IG(1, 1)\n\\tag{5.1}\\]\nEquation 5.1 states that the log-odds of booking status (1 being cancelation and 0 being non-cancelation) is a linear function of \\(m\\) predictors (our 11 features and two interaction terms) weighted by \\(m+1\\) betas (13 for the features and one intercept beta). Our response variable \\(Y\\) is a collection of n number of i.i.d. Bernoulli random variables with probability \\(p\\). Our betas are assumed to be normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). All \\(\\mu\\) values have a normal prior distribution with mean = 0 and standard deviation = 2. All \\(\\sigma\\) values have an inverse gamma prior distribution with shape = 1 and scale = 1."
  },
  {
    "objectID": "posts/welcome/welcome_to_blog.html",
    "href": "posts/welcome/welcome_to_blog.html",
    "title": "Welcome to my blog!",
    "section": "",
    "text": "TL;DR\nThis blog focuses on the use of statistics, particularly bayesian statistics, in the application of business problems. In this post, we review the necessary math background in order to understand future blog posts. As well, we establish expectations for future blog posts and the order in which they are shared.\n\n\nWelcome To My Blog!\nWelcome to my blog! If you are reading this, I hope that means you are as excited about learning statistics as I am about teaching it (and continuing to learn it!). This blog, honestly, is mostly a tool for me to improve my own knowledge in statistics by learning how I would convey it to others. I plan on doing this from a data analysis perspective. Given a certain situation/set of data points, how do we construct the problems we want to solve and implement proper solutions. Particularly, I hope to demonstrate that Bayesian methods can be viable methods to solve problems in business, healthcare, etc. Anyways, I hope you find this blog interesting and useful in your data career. Whether you are just entering data or are an experienced data professional, this blog intends to be a resource in demonstrating good data analysis with sound applied mathematical theory.\n\n\nPrerequisites\nWhile I did mention above that this blog is intended to be useful for beginners and experts alike, I will admit that I will be covering some higher level math, such as:\n\n\nMultivariate Calculus\n\n\nProbability Theory\n\n\nLinear Algebra\n\n\nFor example, suppose we are studying a dataset with a variable that is modeled as an exponential random variable, we would use the below notation to show the probability density function (PDF)\n\\[\\begin{equation}\n\\int_{0}^{\\infty} \\lambda e^{\\lambda x} \\,dx\n\\end{equation}\\]\n\\[\\begin{equation}\nX \\sim Exponential(\\lambda)\n\\end{equation}\\]\nOr, the important Bayes Theorem found below.\n\\[\\begin{equation}\nP(A|B) = \\frac{P(B|A) P(A)}{P(B)}\n\\end{equation}\\]\nDon’t be discourage if the above formulas don’t make sense right now. In each post that these appear, I will breakdown what they mean and their applicability in solving our problem.\n\n\nExpectations\nThe hope of this blog is to present statistics in the form of a data analysis case. For example, let’s say you are a host on AirBnB and want to maximize the number of nights you rent out. How do you properly price your rental given certain parameters (size, geographic setting, etc). We would then present the data points and walk through an analysis of the data by doing the following.\n\n\nExploring the data (EDA) to get to know our dataset\n\n\nConstructing a mathematical framework that can fit our data\n\n\nFit our data to said framework\n\n\nGather inference from our model\n\n\nReview answers explained by our model\n\n\nExplain possible enhancements to our model for future analyses\n\n\nThis will be our attempted framework to blog posts. I hope that by tackling problems in this way, our analytical toolbox will grow and our ability to construct measurable problems from our data will improve. This is the ultimate goal of this blog. I really hope that people will recognize this blog as an opportunity to learn how to think analytically.\n\n\nLet’s do this\nI just want to reiterate that I am excited to learn how to be a better analyst with you by getting to know the math that drives our analytics. I am very passionate about how data can be used to properly drive decision-making in organizations and I hope that this blog motivates you to do the same."
  }
]