{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d5fb6cb-ccc7-4436-a993-d96af6f90917",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"The Doomscrolling Algorithm: Optimizing Content to Maximize Revenue\"\n",
    "draft: false\n",
    "toc: true\n",
    "author: \"Brandon Scott\"\n",
    "date: \"2025-07-05\"\n",
    "number-sections: false\n",
    "categories: [operations, optimization, reinforcement learning, python]\n",
    "execute:\n",
    "    echo: false\n",
    "    warning: false\n",
    "crossref:\n",
    "    chapters: true\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "jupyter: python3\n",
    "bibliography: ../../references.bib\n",
    "csl: ../../ieee.csl\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d07417-01e1-44fb-a2a5-1305ba7a3cff",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22564506-663c-4453-9c00-e1077d98063b",
   "metadata": {},
   "source": [
    "In this post, we present a prototype recommendation system based on *Deep Neural Networks for YouTube Recommendations* [@Covington2016DeepNN] and *Explore, Exploit, Explain: Personalizing Explainable Recommendations with Bandits* [@McInerney2018ExploreEE]. We present the prototype in the context of a company that operates as a short-video content platform. We define the strategy behind the prototype by presenting the business objectives. We follow this by walking through the architecture of the prototype and how it fulfills the objectives of the company. We end by illustrating potential next steps for our company. The code for this prototype can be found at the [github repo.](https://github.com/thebayesianbandit/thebayesianbandit.github.io/blob/main/posts/doom_alg/doom_alg.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2110b-a2ef-400d-b228-33afee8f67d6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9675e2d5-4a74-4fd6-ab84-4a233ee4c7ac",
   "metadata": {},
   "source": [
    "**InstaTok** is a new social media app that specializes in short-video content. The platform operates as a two-sided marketplace. There are user accounts and creator accounts. Anyone can sign-up for a user account for free. To join as a creator, creators must pay a small subscription fee plus a small commission, both billed monthly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc6f3c-0076-4d62-beef-c28537bc6887",
   "metadata": {},
   "source": [
    "Users interact with content via a mobile application. Like other short-video platforms, users are presented a **for-you-page** (FYP) with a single video playing. Users can choose to watch the video as many times as they like or move onto the next video at any time by swipping up on the app. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75737f23-edc2-4f99-b079-685dcea22114",
   "metadata": {},
   "source": [
    "Creators are incentivized to be on the platform by monetizing their videos through advertisements. InstaTok has partnerships with various brands to connect them with creators to advertise their products and services. Creators are then compensated directly by these companies based on their contractual agreements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866fb9fb-7256-4ddc-98b5-6ba7702d9b8b",
   "metadata": {},
   "source": [
    "Since InstaTok is a two-sided platform, we need to optimize experiences for both users and creators. Users need good videos to stay engaged and creators need users to monetize their videos. In order to balance these needs, we can define sound strategy on how we can define the problem and how it can be solved with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd2f15-a9f2-49b6-b787-e887e9d76515",
   "metadata": {},
   "source": [
    "**Note**: While this would technically be a three-sided marketplace since brands also would need to benefit from the platform, we are simplifying this problem to a two-sided one for this post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a2abb-9e71-45ef-a1d0-8518b7baf006",
   "metadata": {},
   "source": [
    "## Company Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055246e9-5cb8-4334-bc62-73df951d699c",
   "metadata": {},
   "source": [
    "As mentioned previously, in order for InstaTok to succeed, we need to develop a product that is appealing to both users and creators. In order to create a sound product that answers to both user and creator needs, we need to develop a robust strategy that will guide our approach to product creation. To do this, we need to answer four questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b356ba-bb9e-4311-9637-094f9744c9b6",
   "metadata": {},
   "source": [
    "1. Where do we compete?\n",
    "2. What unique value do we bring to the market?\n",
    "3. What resources and capabilities can we utilize to deliver unique value?\n",
    "4. How do we sustain our ability to provide unique value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881fd58-eb75-4798-a6af-4cd74b035628",
   "metadata": {},
   "source": [
    "We have established that we are competing in the mobile application market, specifically within the short-video platform arena. We hope to appeal to all ages, but are aiming to capture the college-young professional market. Furthermore, we are looking for those who are looking to separate the world of social media and creative short-video content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d01b0-0af0-41d7-bf37-cd1cd1dcb499",
   "metadata": {},
   "source": [
    "We need to provide unique value to both sides of our market. For our users, we are providing a platform where all content is created by official creators. There are no random company ads appearing in the FYP nor social connection content. We focus the user experience on entertainment content. On top of that, we provide personalization to our users by algorithmically matching them with content they would enjoy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d21ad-ee7f-4d62-9647-6f8533fe06c8",
   "metadata": {},
   "source": [
    "For our creators, we provide unique value through monetization and verified creator status. Creators compete solely with other creators for views, not with general social media users. Additionally, other platforms collect the ad revenue generated by creator content. On our platform, we provide a way for creators to directly collect ad revenue from brands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29dccb-f15d-4dc9-ad0c-68b323ece829",
   "metadata": {},
   "source": [
    "Our key resource and capabilities include our proprietary algorithms, our brand partnerships, and deep technology expertise. These are also key in how we sustain our unique value. By continuing to iterate our algorithms, grow our partnerships, and deepen our technology expertise, we can sustain a unique advantage in this marketplace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a039ed0-0acb-445f-a17e-8f28638f4a07",
   "metadata": {},
   "source": [
    "## From Strategy to Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1a7a6-9641-44d2-b1db-c38801a1c680",
   "metadata": {},
   "source": [
    "We've defined our company strategy, and now we must use it to create a viable product. Our minimum viable product (MVP) should be a mobile application with a user-friendly interface. This interface should provide short-video content to our users one video at a time. Users advance to the next video by swiping up on the screen. These functions should be designed in a way that is intuitive for our target demographic. Additionally, the algorithms powering the service need to be personalized to maximize each user's specific utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f67a8-9e3f-4f90-9ba4-0644695bc491",
   "metadata": {},
   "source": [
    "In this post, we will focus our attention on the personalization algorithms powering our platform. As mentioned, our personalization algorithm is one of our key resources/capabilities in our company strategy. We need it to be incredibly valuable in the eyes of our users and creators. To achieve this, we utilize data to drive our decision making. @tbl-prod-1 shows an example of this kind of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d25dd-5317-4494-ab2b-638a0ac013a8",
   "metadata": {},
   "source": [
    "| Region | Interest |\n",
    "|---|---|\n",
    "| west | tech |\n",
    "| mid | animals |\n",
    "| east | food |\n",
    "\n",
    ": User Interests by Region {#tbl-prod-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62992ad1-7b42-4713-adb9-68af7911f38d",
   "metadata": {},
   "source": [
    "According to our market research, users generally have **two categories** of videos that entice them to keep watching. Furthermore, we learned that users are open to exploring new categories of videos based on their geographic location. For example, those in the midwest appear to be open to exploring videos featuring animals. These insights should drive product development for our personalization algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e26b3-a4e4-49d2-ba71-3d9547e70af4",
   "metadata": {},
   "source": [
    "# Personalization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06759912-5581-4683-a02a-e956055aa6be",
   "metadata": {},
   "source": [
    "## System Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b09032-46ed-4a79-997c-eb80c15aebb6",
   "metadata": {},
   "source": [
    "While previous sections have focused on the business aspects of our product, this section describes the technical details needed to design and implement a personalization system. Our problem can be boiled down to this one question: **how can we optimize our content offerings for any given user such that a creator maximizes their revenue?** To do this, we begin with simple microeconomic theory. We believe that any given user is a rational agent seeking to maximize their utility. We further believe that users have downloaded InstaTok to maiximize their entertainment utility. Therefore, if we provide them with videos that help maximize this utility, they will continue to use the platform (i.e. maximize their watch time per session). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381fb193-5e8b-4ed2-b671-4424b975aeaf",
   "metadata": {},
   "source": [
    "To answer our question on how we can maximize entertainment utility for a given user, we propose a system in @fig-sys-1 that illustrates how we can capture user data to provide meaningful personalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b562ff-157d-4596-9ddf-1f74dc7e6935",
   "metadata": {},
   "source": [
    "![Personalization System Design](doom_diag.jpg){#fig-sys-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e3cb3-1fef-4a43-b4fd-2136dbf3130a",
   "metadata": {},
   "source": [
    "@fig-sys-1 begins with a user opening our app and interacting with a shown video. The interaction data is sent to our data warehouse where it is stored with historical interaction data. Data is then sent from the warehouse to three functions. These functions help define the current state of our user. The first function retrieves current session data pertinent to our given user (e.g. demographic data, location data, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0d9f0-eb06-40d5-a46f-90b33df9749a",
   "metadata": {},
   "source": [
    "The second function is our base recommendation system. The system parses our large video catalog and generates a candidate list of videos that best match user preferences. This list is further refined by adjusting the scores from the base recommendation with additional business logic. We will discuss the base recommendation algorithm in detail later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4656c97-3689-4c70-a53f-0ab40c30c2a2",
   "metadata": {},
   "source": [
    "The third function is our interest prediction layer. To better inform our decision on which video to show the user, we use past interaction data to predict user interest categories. Note: In a true production environment, this would be our approach. However, for the purposes of this post, we randomly generate these interests for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbf59c-a46a-479e-9d27-1dab1013807e",
   "metadata": {},
   "source": [
    "These functions provide output that defines the current state of the user. This state is fed into our reinforcement learning agent (RL agent) which then chooses which action to take (i.e. which video to show the user next). The selection is sent back to the user and the process repeats itself until the user closes the app. We will provide more detail on the RL agent later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1b065-11ff-463b-8d7f-dd2662d5088e",
   "metadata": {},
   "source": [
    "## Recommendation System Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4640b3e2-e699-406f-85b6-871450bac1e1",
   "metadata": {},
   "source": [
    "Our recommendation system is a simple two-phase architecture. The first phase is the initial candidate list generation. To do this, we first assign scores to the interaction data. @tbl-rec-1 shows our assignment scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85941ad9-2cf4-459c-b684-52121e0e0780",
   "metadata": {},
   "source": [
    "| Interaction | Score |\n",
    "|---|---|\n",
    "| watched | 1 |\n",
    "| skipped | -2 |\n",
    "| liked | 2 |\n",
    "| other | -0.5 |\n",
    "\n",
    ": Interaction Scores {#tbl-rec-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5300381-dc6a-4cc0-9236-0e5e2a612ef9",
   "metadata": {},
   "source": [
    "These scores are aggregated to create a item-user matrix, as depicted in @eq-rec-1. Note: For faster computation, we transform this into a sparse matrix using `scipy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a8b82-0847-4462-9680-8cd3489f23d0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{pmatrix}\n",
    "2 & -.5 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "2 & -2 & 1\n",
    "\\end{pmatrix}\n",
    "$${#eq-rec-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c0e89f-a473-41d3-b6fe-98a8caea1c9e",
   "metadata": {},
   "source": [
    "@eq-rec-1 is a $n$ by $m$ matrix where each row $i$ is an item and each column $j$ is a user. The goal of setting the matrix like this is to identify relationships between items. We want to identify which items are most similar to each other based on similar scores from users. To calculate this, we utilize *cosine similarity* [@Salton1975Vector] as shown in @eq-rec-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee5b31-fc50-4594-a8be-bf5f091340ef",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "$${#eq-rec-2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d0eed-9c4a-4bd4-bf92-4ea0709aef45",
   "metadata": {},
   "source": [
    "@eq-rec-2 allows us to measure the cosine of the angle between two item vectors. A smaller angle means higher similarity. Once these are all calculated, the results are stored in a $n$ by $n$ matrix, where each row and column corresponds to a specific item (i.e. an item-item matrix). We can then perform lookups on this matrix to recommend items that are most similar to those a user previously interacted positively with. Once we have $r$ number of recommendations for a user, these items with their respective scores are sent to our weighted-sum function for weighting based on important business objectives. This process of using item-item similarity and weighting according to business objectives is known as *collaborative filtering* [@Sarwar2001]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf9dbd-862c-4849-831a-19eb3bee4a31",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Final Score} = w_{1}\\text{Similarity Score} + w_{2}\\text{Num Views} + w_{3}\\text{Is Interest}\n",
    "$${#eq-rec-3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752e835-f8c2-4b4e-9529-635f192b0afd",
   "metadata": {},
   "source": [
    "The final score of a video is weighted by three key attributes: the similarity score (produced from @eq-rec-1), the number of views a video has (the popularity of it), and a boolean variable indicating whether the video aligns with the user's interests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0aca3-f17b-484d-9435-867e2e6b5ca2",
   "metadata": {},
   "source": [
    "## RL Agent Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807f2ff-6440-4385-985f-ab7c8616d7d0",
   "metadata": {},
   "source": [
    "Our recommendation system currently outputs the top $r$ recommendations for a user based on their past interaction history. This is a great feature, but it does not capture the entire story of a user. Each time a user opens our app, they are in a different state of being. They could be bored, anxious, excited, or experiencing any other emotion. To better understand our users and present them content that aligns with their current state, we utilize reinforcement learning (RL) to model these states and their subsequent feedback. RL is the industry standard for capturing sequential decision making. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb01b98-d6a6-498d-ab74-43a3a37601d4",
   "metadata": {},
   "source": [
    "From a high-level, we refer back to @fig-sys-1. The RL agent takes in current session information (number of videos watched so far, number of skips, last video category show, etc), the candidate list of videos with their final scores, and current \"predicted\" user interests. The RL agent then chooses an action (i.e. which video to show), sends that video to the user, and records the interaction. As the RL agent continues to do this, it learns which states matches certain videos. The more data it has around the interactions between users and videos given current states, the more optimized its **policy** will be at choosing the correct next best video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781a6b6-695a-4f39-9356-7892e3812e57",
   "metadata": {},
   "source": [
    "To model this system, we use a *Deep Q Network (DQN)* [@Mnih2015HumanlevelCT]. The DQN utilizes neural networks to approximate the *Q Function* [@Watkins1989Learning], as shown in @eq-rl-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b96da5-9466-4df2-8be0-6caaa247c115",
   "metadata": {},
   "source": [
    "$$Q^*(s, a) = \\mathbb{E}_{s' \\sim P(\\cdot|s,a)} \\left[ r + \\gamma \\max_{a'} Q^*(s', a') \\right]$${#eq-rl-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019491-50b1-42d0-8cca-8af2c9f12fbb",
   "metadata": {},
   "source": [
    "@eq-rl-1 is the optimal Q-value function for a Q-learning algorithm. The equation basically says that the optimal Q-value for taking action $a$ in state $s$ is equal the expectation of the sum of the immediate reward of taking action $a$ in state $s$ and the optimal Q-value for the next state $s$ over all possible next actions $a$. Simply put, this function estimates the expected future cumulative reward of taking action $a$ in state $s$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f82a75-159c-498b-bd64-6aacf881d7c8",
   "metadata": {},
   "source": [
    "In our DQN, we estimate these Q-values using neural networks. The neural network takes the current state $s$ as input, passes it through the hidden layers, and produces $r$ number of Q-values. The DQN then chooses a video to show the user. To do this, we use an *epsilon-greedy* [@Sutton1998Reinforcement] approach to balance exploration with exploitation. The video is then shown to the user, the user interacts with the video, the interaction is recorded, and the process begins again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037c5b91-d1f0-4e76-8f7d-010feb807486",
   "metadata": {},
   "source": [
    "Our DQN learns is via **experience replay**. The RL agent learns via mini-batches of experiences that are randomly sampled from a \"memory storage\". This breaks correlation and improves training stability. The training is performed like many other DL algorithms where we attempt to minimize a loss function. In our prototype, we use **mean squared error**. The loss is calculated as the difference between our target Q-value and the predicted Q-value, as shown in @eq-rl-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f8bd3-99fc-4034-9211-4d4a0bac9bc5",
   "metadata": {},
   "source": [
    "$$\\min_{\\theta} \\mathcal{L}(\\theta) = \\min_{\\theta} \\mathbb{E} \\left[ \\left( Y - Q(s, a; \\theta) \\right)^2 \\right]$${#eq-rl-2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04892c7-c872-45b5-b60a-c83fe90a5193",
   "metadata": {},
   "source": [
    "Since we don't directly observe target Q-values in the real world, we estimate them via a **target network** in our RL agent. Our predicted Q-values are derived from an entirely different network known as the **online network**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e49fa-17c1-4dfc-98b1-1fb3f9abb2d9",
   "metadata": {},
   "source": [
    "**All specific technical details of the DQN, state and action space, etc. can be found at the github link in the abstract.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8548e73-0ac2-48b6-9c71-9bd77d1fbc46",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39b62c-627a-41a2-a452-aa69a7c9f2ce",
   "metadata": {},
   "source": [
    "In this post, we presented InstaTok, a short-video platform aimed at revolutionizing the short-video entertainment space by providing ad-free experiences to users via a new incentive and verification structure for creators. We walked through the core company strategy and product development on how we can create a prodcut to fulfill the needs of both users and creators. We presented a high-level overview of a user's journey on the app, as well as deeper technical details of how we can algorithmically match users to videos they would enjoy, thereby maximizing their watch time per session. In a real-life scenario where we'd be launching this system, we'd want to implement experiments to properly measure changes in user watch time between different algorithms (e.g. testing a different base recommendation system vs current one to observe its impact on user watch time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e9e888-ca95-4b63-ba47-4b7512c7c7a7",
   "metadata": {},
   "source": [
    "Overall, we hope this post demonstrated the power of recommendation systems and the importance of each layer of the system. Additionally, we hope that readers gained an appreciation for how sound business strategy can guide product development. With both good business strategy and deep technical expertise, one can build an app like TikTok following the principles outlined in this post. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae3411-b38a-4c4f-a42e-d0c2490df0ea",
   "metadata": {},
   "source": [
    "**For code of this prototype, see [github repo.](https://github.com/thebayesianbandit/thebayesianbandit.github.io/blob/main/posts/doom_alg/doom_alg.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab53ac-0a10-42d2-9f88-982c3f1def5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as tdel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45512a0b-648d-4652-831b-f8501cb5f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define video class\n",
    "class Video:\n",
    "    def __init__(self, vid_id, category, duration, creator_id, num_views):\n",
    "        self.vid_id = vid_id\n",
    "        self.category = category\n",
    "        self.duration = duration \n",
    "        self.creator_id = creator_id\n",
    "        self.num_views = num_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "795fba13-660c-4bb3-aee0-1d8327d1c950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define user class\n",
    "class User:\n",
    "    def __init__(self, user_id, age, gender, loc, interests):\n",
    "        self.user_id = user_id\n",
    "        self.age = age\n",
    "        self.gender = gender\n",
    "        self.loc = loc\n",
    "        self.interests = interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefb4c2a-5f45-480c-8eb6-455c932a1491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate videos\n",
    "vids_dict = {}\n",
    "categories = ['comedy', 'educational', 'news', 'food', 'politics', 'animals', 'tech', 'fashion']\n",
    "num_vids = 3000\n",
    "num_creators = 20\n",
    "mean_views = 50\n",
    "sd_views = 10\n",
    "\n",
    "for i in range(num_vids):\n",
    "    vid_id = i\n",
    "    vid_cat = np.random.choice(categories)\n",
    "    vid_dur = 6\n",
    "    vid_creator_id = np.random.choice(num_creators)\n",
    "    num_views = round(np.random.normal(mean_views, sd_views))\n",
    "    \n",
    "    vids_dict[i] = Video(vid_id, vid_cat, vid_dur, vid_creator_id, num_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b341cad-1a16-437b-b427-b2ac6a3b5644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate users\n",
    "users_dict = {}\n",
    "loc = ['west', 'mid', 'east']\n",
    "num_users = 200\n",
    "\n",
    "for i in range(num_users):\n",
    "    user_id = i\n",
    "    user_age = np.random.randint(18, 30)\n",
    "    user_gender = np.random.choice(['m', 'f'])\n",
    "    user_loc = np.random.choice(loc)\n",
    "    user_int = np.random.choice(categories, 2)\n",
    "    \n",
    "    users_dict[i] = User(user_id, user_age, user_gender, user_loc, user_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083ac18d-03b6-4cee-b8ca-cde03dcb24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate interactions\n",
    "actions = ['watched', 'skipped', 'liked']\n",
    "int_dict = {\n",
    "    \"vid_id\": [],\n",
    "    \"user_id\": [],\n",
    "    \"session_id\": [],\n",
    "    \"action\": [],\n",
    "    \"timestamp\": []\n",
    "}\n",
    "num_int_mu = 30\n",
    "num_int_sd = 10\n",
    "\n",
    "for i in users_dict.keys():\n",
    "    current_user = users_dict[i]\n",
    "    current_sess = 0\n",
    "    current_timestamp = 0\n",
    "    num_int = round(max(5, np.random.normal(num_int_mu, num_int_sd)))\n",
    "    \n",
    "    for j in range(num_int):\n",
    "        vid_key = np.random.choice(list(vids_dict.keys()))\n",
    "        current_vid = vids_dict[vid_key]\n",
    "        prob_cont = np.random.uniform()\n",
    "        \n",
    "        if current_vid.category in current_user.interests:\n",
    "            prob_cont = min(1, prob_cont + 0.3)\n",
    "        \n",
    "        if current_vid.category == \"tech\" and current_user.loc == \"west\":\n",
    "            prob_cont = min(1, prob_cont + 0.1)\n",
    "        elif current_vid.category == \"animals\" and current_user.loc == \"mid\":\n",
    "            prob_cont = min(1, prob_cont + 0.1)\n",
    "        elif current_vid.category == \"food\" and current_user.loc == \"east\":\n",
    "            prob_cont = min(1, prob_cont + 0.1)\n",
    "            \n",
    "        if current_vid.category == \"educational\" and current_user.loc == \"west\":\n",
    "            prob_cont = min(1, prob_cont - 0.2)\n",
    "        elif current_vid.category == \"news\" and current_user.loc == \"mid\":\n",
    "            prob_cont = min(1, prob_cont - 0.2)\n",
    "        elif current_vid.category == \"tech\" and current_user.loc == \"east\":\n",
    "            prob_cont = min(1, prob_cont - 0.2)\n",
    "        \n",
    "        comp_prob_cont = 1- prob_cont\n",
    "        action = rd.choices(actions, weights=[prob_cont, comp_prob_cont / 2, comp_prob_cont / 2])[0]\n",
    "        current_vid.num_views += 1\n",
    "        \n",
    "        if action == \"liked\":\n",
    "            prob_cont = min(1, prob_cont + 0.05)\n",
    "            current_timestamp += 6\n",
    "        elif action == \"skipped\":\n",
    "            prob_cont = max(0, prob_cont - 0.3)\n",
    "            current_vid.num_views -= 1\n",
    "            dur = np.random.uniform(1, 5)\n",
    "            current_timestamp += dur\n",
    "        elif action == \"watched\":\n",
    "            current_timestamp += 6\n",
    "        else:\n",
    "            dur = np.random.uniform(1, 5)\n",
    "            current_timestamp += dur\n",
    "        \n",
    "        int_dict[\"vid_id\"].append(current_vid.vid_id)\n",
    "        int_dict[\"user_id\"].append(current_user.user_id)\n",
    "        int_dict[\"session_id\"].append(current_sess)\n",
    "        int_dict[\"timestamp\"].append(current_timestamp)\n",
    "        \n",
    "        if prob_cont < np.random.uniform():\n",
    "            current_sess += 1\n",
    "            current_timestamp += np.random.normal(3600, 400)\n",
    "            action = \"done\"\n",
    "            int_dict[\"action\"].append(action)\n",
    "        else:\n",
    "            int_dict[\"action\"].append(action)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231ba07c-37d2-4691-8399-bd107b08632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform dict to dataframe\n",
    "df = pd.DataFrame(int_dict)\n",
    "df['vid_category'] = df['vid_id'].map(lambda x: vids_dict.get(x).category)\n",
    "df['vid_num_views'] = df['vid_id'].map(lambda x: vids_dict.get(x).num_views)\n",
    "df['user_age'] = df['user_id'].map(lambda x: users_dict.get(x).age)\n",
    "df['user_gender'] = df['user_id'].map(lambda x: users_dict.get(x).gender)\n",
    "df['user_loc'] = df['user_id'].map(lambda x: users_dict.get(x).loc)\n",
    "df['user_int_1'] = df['user_id'].map(lambda x: users_dict.get(x).interests[0])\n",
    "df['user_int_2'] = df['user_id'].map(lambda x: users_dict.get(x).interests[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bf6f34-dea7-4b65-9ca1-c827ec9707a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>action</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>vid_category</th>\n",
       "      <th>vid_num_views</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_int_1</th>\n",
       "      <th>user_int_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>comedy</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>mid</td>\n",
       "      <td>politics</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2837</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>watched</td>\n",
       "      <td>3445.988341</td>\n",
       "      <td>tech</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>mid</td>\n",
       "      <td>politics</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>done</td>\n",
       "      <td>3447.399895</td>\n",
       "      <td>tech</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>mid</td>\n",
       "      <td>politics</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1845</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>watched</td>\n",
       "      <td>6372.084546</td>\n",
       "      <td>educational</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>mid</td>\n",
       "      <td>politics</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>done</td>\n",
       "      <td>6373.976712</td>\n",
       "      <td>tech</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>m</td>\n",
       "      <td>mid</td>\n",
       "      <td>politics</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vid_id  user_id  session_id   action    timestamp vid_category  \\\n",
       "0    2706        0           0     done     6.000000       comedy   \n",
       "1    2837        0           1  watched  3445.988341         tech   \n",
       "2     179        0           1     done  3447.399895         tech   \n",
       "3    1845        0           2  watched  6372.084546  educational   \n",
       "4    1307        0           2     done  6373.976712         tech   \n",
       "\n",
       "   vid_num_views  user_age user_gender user_loc user_int_1 user_int_2  \n",
       "0             59        27           m      mid   politics       food  \n",
       "1             51        27           m      mid   politics       food  \n",
       "2             41        27           m      mid   politics       food  \n",
       "3             47        27           m      mid   politics       food  \n",
       "4             59        27           m      mid   politics       food  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "#View head of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46369f94-68d4-4152-b69b-67b23071175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6134, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "#View shape of df\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f950d3bc-b66e-4e50-82a8-14e773fd3b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Generate score for each interatcion\n",
    "df = df.assign(interaction_score = lambda x: np.where(x.action == \"liked\", 2, \n",
    "                                    np.where(x.action == \"watched\", 1, \n",
    "                                            np.where(x.action == \"skipped\", -1, -.5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909fd5d0-5eb1-4938-a224-c9eb6b0fa753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Aggregate scores and create item-user matrix for cosine similarity\n",
    "sparse_matrix = (df.groupby(['user_id', 'vid_id'])['interaction_score']\n",
    " .sum()\n",
    " .reset_index()\n",
    " .pivot_table(index='vid_id', columns='user_id', values='interaction_score', fill_value=0)\n",
    " .pipe(lambda x: csr_matrix(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246c9fc2-6c17-42f7-986b-9344c6545439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity from sparse matrix\n",
    "cos_sim_mat = cosine_similarity(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef147b1-c66a-41ad-be12-f2336b7ae922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define recommendation function\n",
    "def get_recom(u_id, main_df, sim_mat, num_rec=10):\n",
    "    watched_vids = main_df.query(\"user_id == @u_id\")['vid_id'].tolist()\n",
    "    watched_scores = main_df.query(\"user_id == @u_id\")['interaction_score'].tolist()\n",
    "    look_lst = main_df['vid_id'].sort_values().unique().tolist()\n",
    "    rec_vids = {}\n",
    "    \n",
    "    for i, vid in enumerate(watched_vids):\n",
    "        current_idx = look_lst.index(vid)\n",
    "        for j, item in enumerate(sim_mat[current_idx,:]):\n",
    "            if look_lst[j] not in watched_vids:\n",
    "                rec_vids[look_lst[j]] = rec_vids.get(look_lst[j], 0) + item * watched_scores[i]\n",
    "    \n",
    "    rec_vids = sorted(rec_vids.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return dict(rec_vids[:num_rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff1cc62-34e7-42cb-b713-a0fb8596f278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_rec = get_recom(1, df, cos_sim_mat, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ca77f3-6582-4027-8d5f-c45eb5b54521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define additional scoring function\n",
    "def gen_scores(recs_dict, u_id, w_1, w_2, w_3):\n",
    "    new_dict = {}\n",
    "    current_user = users_dict[u_id]\n",
    "    \n",
    "    for v_id, val in recs_dict.items():\n",
    "        score = 0\n",
    "        current_vid = vids_dict[v_id]\n",
    "        score += (val * w_1) + ((current_vid.num_views * .1) * w_2) + (np.where(current_vid.category in current_user.interests, 1, 0) * w_3)\n",
    "        new_dict[v_id] = score\n",
    "        \n",
    "    new_dict = sorted(new_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return dict(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c53fe291-4b50-4d65-b3ce-bdc586f6c394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create state features\n",
    "df['session_length'] = df['timestamp'] - df.groupby(['user_id', 'session_id'])['timestamp'].transform('min')\n",
    "df['num_vids_session'] = df.groupby(['user_id', 'session_id']).cumcount()\n",
    "df['last_vid_category'] = df.groupby(['user_id', 'session_id'])['vid_category'].shift(1).fillna(\"animals\")\n",
    "df['last_action'] = df.groupby(['user_id', 'session_id'])['action'].shift(1).fillna(\"session_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f76bbf-8af5-4020-ada1-1a93eef0a529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Create state df\n",
    "# state_df = (df.drop(['vid_id', 'interaction_score'], axis=1)\n",
    "#  .pipe(lambda x: pd.get_dummies(x, dtype='float'))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad6d1982-bed1-4b37-80bd-00d46c42ccdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c56fc2f0-1e99-4ac6-8bc7-38ce156db09c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define embedding mappings \n",
    "VID_CATEGORY_MAP = {'comedy': 0, 'educational': 1, 'news': 2, 'food': 3,\n",
    "                    'politics': 4, 'animals': 5, 'tech': 6, 'fashion': 7}\n",
    "USER_GENDER_MAP = {'m': 0, 'f': 1}\n",
    "USER_LOC_MAP = {'west': 0, 'mid': 1, 'east': 2}\n",
    "LAST_ACTION_MAP = {'watched': 0, 'skipped': 1, 'liked': 2, 'session_end': 3}\n",
    "\n",
    "# Define cardinalities\n",
    "NUM_VID_CATEGORIES = len(VID_CATEGORY_MAP) \n",
    "NUM_GENDERS = len(USER_GENDER_MAP)         \n",
    "NUM_LOCS = len(USER_LOC_MAP)               \n",
    "NUM_LAST_ACTIONS = len(LAST_ACTION_MAP)    \n",
    "\n",
    "# Define embedding dims\n",
    "EMBEDDING_DIM_GENDER = 1       \n",
    "EMBEDDING_DIM_LOC = 2          \n",
    "EMBEDDING_DIM_USER_INT = 4     \n",
    "EMBEDDING_DIM_LAST_ACTION = 2\n",
    "EMBEDDING_DIM_VID_CATEGORY = 4 \n",
    "\n",
    "#Define numerical feature dims\n",
    "NUM_NUMERICAL_FEATURES = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e24867a9-1e61-467e-b277-bfb434815b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define state df\n",
    "state_df = df[['user_id', 'user_age', 'num_vids_session', 'session_length', 'user_gender', \n",
    "               'user_loc', 'user_int_1', 'user_int_2', 'last_vid_category', \n",
    "               'last_action']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a14d9a9e-bf17-474e-a110-1f03d26b6ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Deep Q Network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, hidden_dim, action_size):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.user_gender_embedding = nn.Embedding(NUM_GENDERS, EMBEDDING_DIM_GENDER)\n",
    "        self.user_loc_embedding = nn.Embedding(NUM_LOCS, EMBEDDING_DIM_LOC)\n",
    "        self.user_int_1_embedding = nn.Embedding(NUM_VID_CATEGORIES, EMBEDDING_DIM_USER_INT)\n",
    "        self.user_int_2_embedding = nn.Embedding(NUM_VID_CATEGORIES, EMBEDDING_DIM_USER_INT)\n",
    "        self.last_vid_category_embedding = nn.Embedding(NUM_VID_CATEGORIES, EMBEDDING_DIM_USER_INT)\n",
    "        self.last_action_embedding = nn.Embedding(NUM_LAST_ACTIONS, EMBEDDING_DIM_LAST_ACTION)\n",
    "\n",
    "        total_embedding_dim = (\n",
    "            EMBEDDING_DIM_GENDER +\n",
    "            EMBEDDING_DIM_LOC +\n",
    "            EMBEDDING_DIM_USER_INT * 2 + \n",
    "            EMBEDDING_DIM_LAST_ACTION + \n",
    "            EMBEDDING_DIM_VID_CATEGORY\n",
    "        )\n",
    "        \n",
    "        state_dim = NUM_NUMERICAL_FEATURES + total_embedding_dim\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, action_size)\n",
    "    \n",
    "    def forward(self, state_batch):\n",
    "        numerical_features = state_batch[:, :NUM_NUMERICAL_FEATURES]\n",
    "\n",
    "        gender_ids = state_batch[:, NUM_NUMERICAL_FEATURES + 0].long()\n",
    "        loc_ids = state_batch[:, NUM_NUMERICAL_FEATURES + 1].long()\n",
    "        user_int_1_ids = state_batch[:, NUM_NUMERICAL_FEATURES + 2].long()\n",
    "        user_int_2_ids = state_batch[:, NUM_NUMERICAL_FEATURES + 3].long()\n",
    "        last_vid_category_ids = state_batch[:, NUM_NUMERICAL_FEATURES + 4].long()\n",
    "        last_action_ids = state_batch[:, NUM_NUMERICAL_FEATURES + 5].long()\n",
    "\n",
    "        gender_embedded = self.user_gender_embedding(gender_ids)\n",
    "        loc_embedded = self.user_loc_embedding(loc_ids)\n",
    "        user_int_1_embedded = self.user_int_1_embedding(user_int_1_ids)\n",
    "        user_int_2_embedded = self.user_int_2_embedding(user_int_2_ids)\n",
    "        last_vid_category_embedded = self.last_vid_category_embedding(last_vid_category_ids)\n",
    "        last_action_embedded = self.last_action_embedding(last_action_ids)\n",
    "\n",
    "        x = torch.cat((\n",
    "            numerical_features,\n",
    "            gender_embedded,\n",
    "            loc_embedded,\n",
    "            user_int_1_embedded,\n",
    "            user_int_2_embedded,\n",
    "            last_vid_category_embedded,\n",
    "            last_action_embedded\n",
    "        ), dim=1)\n",
    "\n",
    "        # Pass through the dense layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b74cc9-395d-4eef-a78a-04f61002399f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Agent\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size, model, optimizer, criterion):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if rd.random() <= self.epsilon:\n",
    "            return rd.randrange(self.action_size)\n",
    "        with torch.no_grad():\n",
    "            act_values = self.model(state.unsqueeze(0))\n",
    "        return torch.argmax(act_values[0]).item()\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = rd.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*minibatch)\n",
    "\n",
    "        states = torch.stack(states)\n",
    "        actions = torch.tensor(actions, dtype=torch.long)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        next_states = torch.stack(next_states)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "        q_values = self.model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        next_q_values = self.model(next_states).max(1)[0]\n",
    "        targets = rewards + (1 - dones) * self.gamma * next_q_values\n",
    "\n",
    "        loss = self.criterion(q_values, targets)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f006375-a02e-4898-bfe2-813079f48e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define get state function\n",
    "def get_state(current_s, v_scores):\n",
    "    state_vec = torch.zeros(9+len(v_scores))\n",
    "    \n",
    "    state_vec[0] = current_s['user_age']\n",
    "    state_vec[1] = current_s['num_vids_session']\n",
    "    state_vec[2] = current_s['session_length']\n",
    "    \n",
    "    for i in range(len(v_scores)):\n",
    "        state_vec[3+i]\n",
    "    \n",
    "    state_vec[3+len(v_scores)] = USER_GENDER_MAP.get(current_s['user_gender'])\n",
    "    state_vec[4+len(v_scores)] = USER_LOC_MAP.get(current_s['user_loc'])\n",
    "    state_vec[5+len(v_scores)] = VID_CATEGORY_MAP.get(current_s['user_int_1'])\n",
    "    state_vec[6+len(v_scores)] = VID_CATEGORY_MAP.get(current_s['user_int_2'])\n",
    "    state_vec[7+len(v_scores)] = VID_CATEGORY_MAP.get(current_s['last_vid_category'])\n",
    "    state_vec[8+len(v_scores)] = LAST_ACTION_MAP.get(current_s['last_action'])\n",
    "    \n",
    "    return state_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dca64f7-9f46-45ce-b4ca-83ee484083ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define reward function\n",
    "def get_reward(current_action):\n",
    "    reward = 0\n",
    "    done_bool = False\n",
    "    \n",
    "    if current_action == \"watched\":\n",
    "        reward += 1\n",
    "    elif current_action == \"liked\":\n",
    "        reward += 2\n",
    "    elif current_action == \"skipped\":\n",
    "        reward -= 2\n",
    "    else:\n",
    "        reward -= .5\n",
    "        done_bool = True\n",
    "    \n",
    "    return reward, done_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "043201c8-3c77-4bf4-a809-8bb4053de0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define update function for similarity matrix\n",
    "def update_sim_mat(temp_df):\n",
    "    temp_sparse_matrix = (temp_df.groupby(['user_id', 'vid_id'])['interaction_score']\n",
    "                     .sum()\n",
    "                     .reset_index()\n",
    "                     .pivot_table(index='vid_id', columns='user_id', values='interaction_score', fill_value=0)\n",
    "                     .pipe(lambda x: csr_matrix(x))\n",
    "                    )\n",
    "    \n",
    "    temp_cos_sim_mat = cosine_similarity(temp_sparse_matrix)\n",
    "    \n",
    "    return temp_cos_sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5452433-4cf3-458e-ab3f-a842781941cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define parameters for DQN\n",
    "hidden_lay_size = 64\n",
    "action_size = 10\n",
    "mod = DQN(hidden_lay_size, action_size)\n",
    "optimizer = optim.Adam(mod.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c36957a4-34b7-4b70-b7d8-c3ebdca77e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define parameters for Agent\n",
    "agent = Agent(mod.state_dim, action_size, mod, optimizer, criterion)\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb5e1df8-913e-440b-967b-7a8d7ac3942d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define RL actions\n",
    "actions_rl = ['watched', 'skipped', 'liked', 'session_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50ae6153-9bfc-4f05-90e9-000b76385995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define simulation function\n",
    "def perf_sim(n_eps, n_steps, sim_df):\n",
    "    rewards_per_episode = []\n",
    "    losses_per_episode = []\n",
    "    \n",
    "    sim_dict = {\n",
    "        'user_id': [],\n",
    "        'user_age': [],\n",
    "        'time_step': [],\n",
    "        'num_vids_session': [],\n",
    "        'session_length': [],\n",
    "        'user_gender': [],\n",
    "        'user_loc': [],\n",
    "        'user_int_1': [],\n",
    "        'user_int_2': [],\n",
    "        'last_vid_category': [],\n",
    "        'last_action': [],\n",
    "        'current_vid_rec': [],\n",
    "        'action': [],\n",
    "        'interaction_score': []\n",
    "    }\n",
    "    \n",
    "    temp_sim_df = sim_df.copy()\n",
    "    \n",
    "    for e in range(n_eps):\n",
    "        total_reward = 0\n",
    "        \n",
    "        next_state_dict = {}\n",
    "        \n",
    "        current_user_id = np.random.choice(list(users_dict.keys()))\n",
    "        current_user = users_dict[current_user_id]\n",
    "        \n",
    "        current_state = state_df.query(\"user_id == @current_user_id\").drop(['user_id'], axis=1).iloc[-1]\n",
    "        current_state['num_vids_session'] = 0\n",
    "        current_state['session_length'] = 0\n",
    "        \n",
    "        last_vid_cat = current_state['last_vid_category']\n",
    "        last_action = current_state['last_action']\n",
    "        \n",
    "        cos_sim_mat = update_sim_mat(temp_sim_df)\n",
    "        current_vid_cand = get_recom(current_user_id, temp_sim_df, cos_sim_mat, action_size)\n",
    "        current_vid_cand = gen_scores(current_vid_cand, current_user_id, .5, .1, .3)\n",
    "        vid_scores = [score for score in current_vid_cand.values()]\n",
    "        \n",
    "        current_state = current_state.to_dict()\n",
    "        current_state = get_state(current_state, vid_scores)\n",
    "        \n",
    "        session_len = 0\n",
    "        num_vids_sess = 0\n",
    "        \n",
    "        for t in range(n_steps):\n",
    "            chosen_vid_idx = agent.act(current_state)\n",
    "            chosen_vid_key = list(current_vid_cand.keys())[chosen_vid_idx]\n",
    "            chosen_vid = vids_dict[chosen_vid_key]\n",
    "            \n",
    "            prob_cont = np.random.uniform()\n",
    "\n",
    "            if chosen_vid.category in current_user.interests:\n",
    "                prob_cont = min(1, prob_cont + 0.3)\n",
    "\n",
    "            if chosen_vid.category == \"tech\" and current_user.loc == \"west\":\n",
    "                prob_cont = min(1, prob_cont + 0.1)\n",
    "            elif chosen_vid.category == \"animals\" and current_user.loc == \"mid\":\n",
    "                prob_cont = min(1, prob_cont + 0.1)\n",
    "            elif chosen_vid.category == \"food\" and current_user.loc == \"east\":\n",
    "                prob_cont = min(1, prob_cont + 0.1)\n",
    "\n",
    "            if chosen_vid.category == \"educational\" and current_user.loc == \"west\":\n",
    "                prob_cont = min(1, prob_cont - 0.2)\n",
    "            elif chosen_vid.category == \"news\" and current_user.loc == \"mid\":\n",
    "                prob_cont = min(1, prob_cont - 0.2)\n",
    "            elif chosen_vid.category == \"tech\" and current_user.loc == \"east\":\n",
    "                prob_cont = min(1, prob_cont - 0.2)\n",
    "\n",
    "            comp_prob_cont = 1- prob_cont\n",
    "            action = rd.choices(actions_rl, weights=[prob_cont, comp_prob_cont / 3, comp_prob_cont / 3, comp_prob_cont / 3])[0]\n",
    "            chosen_vid.num_views += 1\n",
    "\n",
    "            current_reward, current_done = get_reward(action)\n",
    "            \n",
    "            sim_dict['user_id'].append(current_user_id)\n",
    "            sim_dict['user_age'].append(current_user.age)\n",
    "            sim_dict['time_step'].append(t)\n",
    "            sim_dict['user_gender'].append(current_user.gender)\n",
    "            sim_dict['user_loc'].append(current_user.loc)\n",
    "            sim_dict['user_int_1'].append(current_user.interests[0])\n",
    "            sim_dict['user_int_2'].append(current_user.interests[1])\n",
    "            sim_dict['last_vid_category'].append(last_vid_cat)\n",
    "            sim_dict['last_action'].append(last_action)\n",
    "            sim_dict['current_vid_rec'].append(chosen_vid_key)\n",
    "            sim_dict['action'].append(action)\n",
    "            sim_dict['interaction_score'].append(current_reward)\n",
    "            \n",
    "            if action == 'session_end' or action == 'skipped':\n",
    "                session_len += np.random.uniform(1, 5)\n",
    "            else:\n",
    "                session_len += 6\n",
    "                num_vids_sess += 1\n",
    "            \n",
    "            sim_dict['session_length'].append(session_len)\n",
    "            sim_dict['num_vids_session'].append(num_vids_sess)\n",
    "            \n",
    "            next_state_dict['user_id'] = current_user_id\n",
    "            next_state_dict['user_age'] = current_user.age\n",
    "            next_state_dict['time_step'] = t + 1\n",
    "            next_state_dict['user_gender'] = current_user.gender\n",
    "            next_state_dict['user_loc'] = current_user.loc\n",
    "            next_state_dict['user_int_1'] = current_user.interests[0]\n",
    "            next_state_dict['user_int_2'] = current_user.interests[1]\n",
    "            next_state_dict['last_vid_category'] = chosen_vid.category\n",
    "            next_state_dict['last_action'] = action\n",
    "            next_state_dict['session_length'] = session_len\n",
    "            next_state_dict['num_vids_session'] = num_vids_sess\n",
    "            \n",
    "            cos_sim_mat = update_sim_mat(temp_sim_df)\n",
    "            current_vid_cand = get_recom(current_user_id, temp_sim_df, cos_sim_mat, action_size)\n",
    "            current_vid_cand = gen_scores(current_vid_cand, current_user_id, .5, .1, .3)\n",
    "            vid_scores = [score for score in current_vid_cand.values()]\n",
    "            \n",
    "            next_state = get_state(next_state_dict, vid_scores)\n",
    "            \n",
    "            agent.remember(current_state, chosen_vid_idx, current_reward, next_state, current_done)\n",
    "            loss_item = agent.replay(batch_size)\n",
    "            \n",
    "            if loss_item is not None:\n",
    "                losses_per_episode.append(loss_item)\n",
    "            \n",
    "            total_reward += current_reward\n",
    "            \n",
    "            current_state = next_state\n",
    "            last_vid_cat = chosen_vid.category\n",
    "            last_action = action\n",
    "            \n",
    "            new_data = {'vid_id': [chosen_vid_key], 'user_id': [current_user_id], 'interaction_score': [current_reward]}\n",
    "            temp_sim_df = pd.concat([temp_sim_df, pd.DataFrame(new_data)], ignore_index=True)\n",
    "            \n",
    "            if current_done:\n",
    "                break\n",
    "                \n",
    "        rewards_per_episode.append(total_reward)\n",
    "        \n",
    "        if (e + 1) % 10 == 0:\n",
    "            avg_reward = np.mean(rewards_per_episode)\n",
    "            avg_loss = np.mean(losses_per_episode)\n",
    "            \n",
    "            print(f\"Avg Reward: {avg_reward:.2f}\")\n",
    "            print(f\"Avg Loss: {avg_loss:.2f}\")\n",
    "    \n",
    "    return rewards_per_episode, losses_per_episode, pd.DataFrame(sim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60227a24-90d9-486a-af67-3ca7331dc35a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Perform simulation\n",
    "# total_rew, total_loss, rl_df = perf_sim(500, 50, df[['vid_id', 'user_id', 'interaction_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64a628f7-076e-49d9-8961-ea591087fcda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Save rl_df\n",
    "# rl_df.to_csv(\"rl_sim_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05ff4642-8081-49ef-8e3c-a6f03be0726b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load rl_df\n",
    "rl_df = pd.read_csv(\"rl_sim_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e69cddc9-e8ee-4198-aaab-ff8d2ffafeed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_age</th>\n",
       "      <th>time_step</th>\n",
       "      <th>num_vids_session</th>\n",
       "      <th>session_length</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_int_1</th>\n",
       "      <th>user_int_2</th>\n",
       "      <th>last_vid_category</th>\n",
       "      <th>last_action</th>\n",
       "      <th>current_vid_rec</th>\n",
       "      <th>action</th>\n",
       "      <th>interaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>comedy</td>\n",
       "      <td>watched</td>\n",
       "      <td>1336</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>fashion</td>\n",
       "      <td>watched</td>\n",
       "      <td>1826</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>tech</td>\n",
       "      <td>watched</td>\n",
       "      <td>452</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>tech</td>\n",
       "      <td>watched</td>\n",
       "      <td>1683</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>animals</td>\n",
       "      <td>watched</td>\n",
       "      <td>484</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>food</td>\n",
       "      <td>watched</td>\n",
       "      <td>204</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>news</td>\n",
       "      <td>watched</td>\n",
       "      <td>2960</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>98</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>43.242581</td>\n",
       "      <td>f</td>\n",
       "      <td>mid</td>\n",
       "      <td>tech</td>\n",
       "      <td>animals</td>\n",
       "      <td>tech</td>\n",
       "      <td>watched</td>\n",
       "      <td>445</td>\n",
       "      <td>session_end</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>m</td>\n",
       "      <td>west</td>\n",
       "      <td>food</td>\n",
       "      <td>tech</td>\n",
       "      <td>fashion</td>\n",
       "      <td>skipped</td>\n",
       "      <td>728</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>m</td>\n",
       "      <td>west</td>\n",
       "      <td>food</td>\n",
       "      <td>tech</td>\n",
       "      <td>fashion</td>\n",
       "      <td>watched</td>\n",
       "      <td>752</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  user_age  time_step  num_vids_session  session_length user_gender  \\\n",
       "0       98        25          0                 1        6.000000           f   \n",
       "1       98        25          1                 2       12.000000           f   \n",
       "2       98        25          2                 3       18.000000           f   \n",
       "3       98        25          3                 4       24.000000           f   \n",
       "4       98        25          4                 5       30.000000           f   \n",
       "5       98        25          5                 6       36.000000           f   \n",
       "6       98        25          6                 7       42.000000           f   \n",
       "7       98        25          7                 7       43.242581           f   \n",
       "8       30        26          0                 1        6.000000           m   \n",
       "9       30        26          1                 2       12.000000           m   \n",
       "\n",
       "  user_loc user_int_1 user_int_2 last_vid_category last_action  \\\n",
       "0      mid       tech    animals            comedy     watched   \n",
       "1      mid       tech    animals           fashion     watched   \n",
       "2      mid       tech    animals              tech     watched   \n",
       "3      mid       tech    animals              tech     watched   \n",
       "4      mid       tech    animals           animals     watched   \n",
       "5      mid       tech    animals              food     watched   \n",
       "6      mid       tech    animals              news     watched   \n",
       "7      mid       tech    animals              tech     watched   \n",
       "8     west       food       tech           fashion     skipped   \n",
       "9     west       food       tech           fashion     watched   \n",
       "\n",
       "   current_vid_rec       action  interaction_score  \n",
       "0             1336      watched                1.0  \n",
       "1             1826      watched                1.0  \n",
       "2              452      watched                1.0  \n",
       "3             1683      watched                1.0  \n",
       "4              484      watched                1.0  \n",
       "5              204      watched                1.0  \n",
       "6             2960      watched                1.0  \n",
       "7              445  session_end               -0.5  \n",
       "8              728      watched                1.0  \n",
       "9              752      watched                1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "#Show rl_df\n",
    "rl_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "319a1787-21b8-423c-9494-a19bf48dbad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_age</th>\n",
       "      <th>time_step</th>\n",
       "      <th>num_vids_session</th>\n",
       "      <th>session_length</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>user_int_1</th>\n",
       "      <th>user_int_2</th>\n",
       "      <th>last_vid_category</th>\n",
       "      <th>last_action</th>\n",
       "      <th>current_vid_rec</th>\n",
       "      <th>action</th>\n",
       "      <th>interaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>tech</td>\n",
       "      <td>liked</td>\n",
       "      <td>1</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>educational</td>\n",
       "      <td>watched</td>\n",
       "      <td>2271</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>tech</td>\n",
       "      <td>watched</td>\n",
       "      <td>1115</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>fashion</td>\n",
       "      <td>watched</td>\n",
       "      <td>2495</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>fashion</td>\n",
       "      <td>watched</td>\n",
       "      <td>618</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>news</td>\n",
       "      <td>watched</td>\n",
       "      <td>397</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>40.464115</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "      <td>watched</td>\n",
       "      <td>1547</td>\n",
       "      <td>skipped</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>46.464115</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>educational</td>\n",
       "      <td>skipped</td>\n",
       "      <td>1242</td>\n",
       "      <td>liked</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>52.464115</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>animals</td>\n",
       "      <td>liked</td>\n",
       "      <td>2546</td>\n",
       "      <td>watched</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>57.077824</td>\n",
       "      <td>f</td>\n",
       "      <td>west</td>\n",
       "      <td>fashion</td>\n",
       "      <td>food</td>\n",
       "      <td>comedy</td>\n",
       "      <td>watched</td>\n",
       "      <td>387</td>\n",
       "      <td>session_end</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  user_age  time_step  num_vids_session  session_length  \\\n",
       "3319       55        28          0                 1        6.000000   \n",
       "3320       55        28          1                 2       12.000000   \n",
       "3321       55        28          2                 3       18.000000   \n",
       "3322       55        28          3                 4       24.000000   \n",
       "3323       55        28          4                 5       30.000000   \n",
       "3324       55        28          5                 6       36.000000   \n",
       "3325       55        28          6                 6       40.464115   \n",
       "3326       55        28          7                 7       46.464115   \n",
       "3327       55        28          8                 8       52.464115   \n",
       "3328       55        28          9                 8       57.077824   \n",
       "\n",
       "     user_gender user_loc user_int_1 user_int_2 last_vid_category last_action  \\\n",
       "3319           f     west    fashion       food              tech       liked   \n",
       "3320           f     west    fashion       food       educational     watched   \n",
       "3321           f     west    fashion       food              tech     watched   \n",
       "3322           f     west    fashion       food           fashion     watched   \n",
       "3323           f     west    fashion       food           fashion     watched   \n",
       "3324           f     west    fashion       food              news     watched   \n",
       "3325           f     west    fashion       food              food     watched   \n",
       "3326           f     west    fashion       food       educational     skipped   \n",
       "3327           f     west    fashion       food           animals       liked   \n",
       "3328           f     west    fashion       food            comedy     watched   \n",
       "\n",
       "      current_vid_rec       action  interaction_score  \n",
       "3319                1      watched                1.0  \n",
       "3320             2271      watched                1.0  \n",
       "3321             1115      watched                1.0  \n",
       "3322             2495      watched                1.0  \n",
       "3323              618      watched                1.0  \n",
       "3324              397      watched                1.0  \n",
       "3325             1547      skipped               -2.0  \n",
       "3326             1242        liked                2.0  \n",
       "3327             2546      watched                1.0  \n",
       "3328              387  session_end               -0.5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "#Show rl_df tail\n",
    "rl_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "700661bb-4f36-4236-b3f7-b37c6bb0fc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Show rewards and losses\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "# ax[0].plot(total_rew)\n",
    "# ax[0].set_title(\"Total Rewards per Episode\")\n",
    "# ax[1].plot(total_loss)\n",
    "# ax[1].set_title(\"Total Loss per Episode\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a14ba-79b3-4783-b85b-a6adaf41fbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
